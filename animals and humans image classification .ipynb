{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(PATH, 'images_data')\n",
    "data_dir_list = os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cats', 'Dogs', 'Horses', 'Humans']\n"
     ]
    }
   ],
   "source": [
    "print(data_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows=224\n",
    "img_cols=224\n",
    "num_channel=3\n",
    "\n",
    "num_epoch=10\n",
    "batch_size=32\n",
    "\n",
    "img_data_list=[]\n",
    "classes_names_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from Cats folder\n",
      "\n",
      "Loading images from Dogs folder\n",
      "\n",
      "Loading images from Horses folder\n",
      "\n",
      "Loading images from Humans folder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    classes_names_list.append(dataset) \n",
    "    print ('Loading images from {} folder\\n'.format(dataset)) \n",
    "    img_list=os.listdir(DATA_PATH+'/'+ dataset)\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(DATA_PATH + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(img_rows, img_cols))\n",
    "        img_data_list.append(input_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(classes_names_list)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = img_data.shape[0]\n",
    "input_shape = img_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.ones((num_of_samples,), dtype='int64')\n",
    "\n",
    "classes[0:202]=0\n",
    "classes[202:404]=1\n",
    "classes[404:606]=2\n",
    "classes[606:]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "classes = to_categorical(classes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, Y = shuffle(img_data, classes, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 220, 220, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 108, 108, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 106, 106, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 179776)            0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                11505728  \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 11,571,556\n",
      "Trainable params: 11,571,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x1dbac25b860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1dbac25bcf8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1db9d32f390>,\n",
       " <keras.layers.core.Dropout at 0x1dbac341fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1dbac351a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1dbac341a90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1dbac3b0ef0>,\n",
       " <keras.layers.core.Dropout at 0x1dbac46d9b0>,\n",
       " <keras.layers.core.Flatten at 0x1dbac4a3518>,\n",
       " <keras.layers.core.Dense at 0x1dbac46dfd0>,\n",
       " <keras.layers.core.Dropout at 0x1dbac46d630>,\n",
       " <keras.layers.core.Dense at 0x1db953f7908>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_32/kernel:0' shape=(3, 3, 3, 32) dtype=float32, numpy=\n",
       " array([[[[ 0.07678224,  0.09463818, -0.12440526,  0.11993076,\n",
       "            0.13325201,  0.1008423 ,  0.11898859,  0.00636776,\n",
       "            0.04068914, -0.02384677,  0.01979248,  0.05982994,\n",
       "           -0.02069925,  0.09641643,  0.02204329,  0.08712244,\n",
       "           -0.02213232,  0.118082  , -0.02963553,  0.06735153,\n",
       "           -0.01118872, -0.08326   ,  0.00621304, -0.12266005,\n",
       "           -0.08321426,  0.0273613 , -0.03178767, -0.09314308,\n",
       "            0.08756451,  0.13676934, -0.02963822, -0.08688299],\n",
       "          [ 0.02434   , -0.13766342, -0.02652779, -0.09675057,\n",
       "           -0.08460203, -0.11057214, -0.08729921,  0.03984269,\n",
       "           -0.12685484, -0.05976643, -0.08632496, -0.01598549,\n",
       "            0.06277286, -0.01991108, -0.01512282, -0.08341686,\n",
       "            0.02651992,  0.08315016, -0.01190893, -0.05064309,\n",
       "           -0.00458997, -0.10463008, -0.06552032, -0.00512192,\n",
       "           -0.09466967,  0.01916309, -0.11988015, -0.06785376,\n",
       "            0.04645592,  0.04443184, -0.04142933, -0.03349409],\n",
       "          [ 0.10782169,  0.01696582, -0.07012901,  0.05973418,\n",
       "           -0.10929228,  0.10911848,  0.09359549,  0.06347142,\n",
       "            0.06975412, -0.13520122,  0.08726771, -0.02483734,\n",
       "            0.11990254,  0.03723721, -0.04094086, -0.12418921,\n",
       "           -0.08682258,  0.06170657,  0.02803424, -0.05942389,\n",
       "           -0.04311232,  0.12195058, -0.07646718, -0.09703662,\n",
       "           -0.02984161, -0.01804093,  0.09932038, -0.11596072,\n",
       "           -0.05631287,  0.10741597,  0.05789779, -0.0304312 ]],\n",
       " \n",
       "         [[-0.04272203, -0.04832722, -0.01041795,  0.0683393 ,\n",
       "            0.01187913,  0.1188222 , -0.13230766,  0.05574803,\n",
       "           -0.12852728, -0.12229612,  0.03429434,  0.03769153,\n",
       "           -0.00583653,  0.00171177,  0.07400754, -0.13219965,\n",
       "            0.02533373,  0.0930194 ,  0.01505955, -0.1268905 ,\n",
       "            0.0978239 ,  0.10667032,  0.08115906,  0.10146746,\n",
       "            0.10020362, -0.09373964,  0.01622559,  0.07378681,\n",
       "            0.1360765 ,  0.05009654, -0.06225852,  0.00378828],\n",
       "          [ 0.06742646,  0.01328278, -0.03447643, -0.09153883,\n",
       "           -0.05825577,  0.10770126, -0.10084262, -0.06013662,\n",
       "            0.05474304, -0.06883574,  0.00393055,  0.05523328,\n",
       "           -0.07827922,  0.00324942,  0.0151203 , -0.10286252,\n",
       "            0.00390485,  0.00137433,  0.13401477, -0.04197088,\n",
       "           -0.11637515, -0.13395248,  0.05507499,  0.12770377,\n",
       "           -0.11547007,  0.00624537, -0.02293086,  0.03409667,\n",
       "           -0.00025374,  0.03627932,  0.11487286,  0.01043832],\n",
       "          [ 0.09564376,  0.01916227,  0.07437311,  0.00791655,\n",
       "            0.10115138, -0.07252409,  0.08001044,  0.1370575 ,\n",
       "           -0.13270509,  0.02276647, -0.09640679,  0.12127234,\n",
       "           -0.04684143,  0.07972786,  0.06012954,  0.10872772,\n",
       "            0.12428243, -0.13384679,  0.10533085, -0.06999258,\n",
       "            0.12956588, -0.05159645, -0.00048463, -0.0541522 ,\n",
       "            0.11245291, -0.05392555,  0.10339816, -0.0049763 ,\n",
       "            0.08900826, -0.03448886, -0.0141619 ,  0.04692672]],\n",
       " \n",
       "         [[-0.10715096,  0.03482361, -0.12652084,  0.057237  ,\n",
       "            0.01514095, -0.08278064,  0.05407146,  0.01985705,\n",
       "           -0.06669607,  0.03571552, -0.01642997, -0.0042782 ,\n",
       "           -0.12011473,  0.04226817,  0.08711764,  0.04182988,\n",
       "           -0.07341048,  0.03448689, -0.07949831,  0.12277339,\n",
       "            0.03726736,  0.04598787,  0.04095125, -0.04977451,\n",
       "           -0.0132025 , -0.01408099, -0.03594721,  0.06971592,\n",
       "            0.01043658,  0.04269183,  0.01545487, -0.09245968],\n",
       "          [-0.0811757 ,  0.13499768,  0.08428802,  0.02757637,\n",
       "            0.11979045,  0.07099289,  0.07897872,  0.08474039,\n",
       "            0.01857692,  0.13501163,  0.00309487,  0.02303825,\n",
       "            0.01912968,  0.04672623,  0.08546558, -0.05692832,\n",
       "            0.12209661,  0.09511876,  0.04526463,  0.03479919,\n",
       "            0.11943112,  0.04827219,  0.11694826, -0.03744481,\n",
       "           -0.13036013, -0.1018068 , -0.12251671,  0.11952044,\n",
       "           -0.00528219,  0.04167756, -0.04551322, -0.1273404 ],\n",
       "          [-0.01269135, -0.03261809,  0.05368835,  0.0033614 ,\n",
       "           -0.08215404,  0.09377722, -0.10609244, -0.03174585,\n",
       "            0.11857666,  0.1009267 ,  0.11935304, -0.07959673,\n",
       "            0.11872061,  0.08170554,  0.11835845, -0.03789722,\n",
       "           -0.1011342 ,  0.04837769,  0.09202501, -0.00238027,\n",
       "           -0.07222212, -0.06748415,  0.03193922, -0.10065603,\n",
       "            0.00943139, -0.01183832, -0.03346816, -0.03087706,\n",
       "            0.09040497, -0.09083928, -0.02625425, -0.05107787]]],\n",
       " \n",
       " \n",
       "        [[[-0.08709224,  0.02485383,  0.07953648, -0.00818367,\n",
       "            0.06382811,  0.07509267, -0.12523426, -0.12479841,\n",
       "           -0.10490826, -0.09033462,  0.11364491,  0.13418885,\n",
       "           -0.04064418,  0.1179121 , -0.12664342, -0.1077932 ,\n",
       "            0.03382798, -0.03305747, -0.01333342, -0.00379594,\n",
       "           -0.00904815,  0.08412845,  0.05631043, -0.05596164,\n",
       "           -0.10033865,  0.07998794, -0.05775654,  0.08700109,\n",
       "           -0.1336156 , -0.12510228, -0.08954197, -0.07143612],\n",
       "          [ 0.10677965,  0.10395424, -0.08381297,  0.04679246,\n",
       "            0.02089588,  0.09269384,  0.12106858,  0.10914275,\n",
       "            0.03203481, -0.0829473 , -0.06728767, -0.03627521,\n",
       "            0.01409961, -0.09792791,  0.02101184,  0.03185076,\n",
       "           -0.07612717,  0.0573142 , -0.0447926 , -0.00727758,\n",
       "            0.11450307,  0.12065111, -0.11007863, -0.04836246,\n",
       "           -0.08647787,  0.13370334,  0.05078031,  0.09177674,\n",
       "           -0.12356796,  0.05768506,  0.08885518, -0.11561716],\n",
       "          [ 0.06519356, -0.02588855, -0.12492259,  0.08162038,\n",
       "            0.05476496,  0.05425826, -0.05330418, -0.03134096,\n",
       "            0.10902308, -0.02814286, -0.06645188, -0.07812628,\n",
       "            0.13475631, -0.0939555 ,  0.10598691, -0.07944323,\n",
       "            0.06242976, -0.12744541,  0.05801919, -0.07815151,\n",
       "            0.10664491, -0.12058777,  0.02447627,  0.09193027,\n",
       "           -0.11735575,  0.07278526,  0.10174188, -0.13534452,\n",
       "           -0.05198074, -0.0068655 , -0.03451782, -0.1297827 ]],\n",
       " \n",
       "         [[-0.10784581,  0.05752568,  0.0630772 ,  0.11922221,\n",
       "            0.12293349,  0.12732257,  0.10506798, -0.11182915,\n",
       "            0.0952633 , -0.01039535,  0.03345966, -0.04766349,\n",
       "           -0.08282118, -0.05277263, -0.12727115,  0.11837806,\n",
       "            0.05549361, -0.10478941, -0.02278759,  0.00669038,\n",
       "            0.12253661, -0.05313399, -0.00231835,  0.13039728,\n",
       "           -0.06637193, -0.12352433, -0.01475817, -0.03521153,\n",
       "            0.0555065 , -0.09202372,  0.00630409, -0.0897063 ],\n",
       "          [ 0.12695278, -0.1002559 ,  0.03201692,  0.10607286,\n",
       "           -0.0362786 , -0.02126087,  0.01911044,  0.12546222,\n",
       "            0.03261098, -0.06316209, -0.04789708, -0.07687299,\n",
       "            0.10835341,  0.00424473, -0.02304632, -0.05261443,\n",
       "            0.09106342, -0.07554226,  0.06485961,  0.02688396,\n",
       "           -0.07027711,  0.07423609,  0.01924983,  0.03030393,\n",
       "            0.11215569, -0.07672265, -0.04320649,  0.0401523 ,\n",
       "           -0.03874462, -0.00265168,  0.03186138, -0.10117678],\n",
       "          [ 0.07849257, -0.0864656 , -0.13576284,  0.029479  ,\n",
       "           -0.01123281, -0.10249939,  0.00400235,  0.13635175,\n",
       "            0.0995845 , -0.05061022,  0.13428508,  0.02216299,\n",
       "            0.00250304,  0.02311946,  0.0529381 , -0.10714385,\n",
       "           -0.07772221,  0.07840274,  0.02332219, -0.00340049,\n",
       "           -0.05572055,  0.0906039 ,  0.03431112, -0.00039743,\n",
       "           -0.02800795,  0.1290129 , -0.10149013,  0.04700236,\n",
       "            0.05279392, -0.03023288, -0.06452606, -0.11341223]],\n",
       " \n",
       "         [[-0.0237877 , -0.08361544,  0.05352236, -0.10709199,\n",
       "            0.03577344, -0.06482477,  0.00604726,  0.11441936,\n",
       "            0.03915209,  0.05103746, -0.00279267, -0.08520734,\n",
       "            0.13452081,  0.08835207,  0.03350899, -0.04932696,\n",
       "            0.12356995,  0.04060335,  0.11643119, -0.08141729,\n",
       "           -0.09269169, -0.09059397,  0.13395758, -0.04303091,\n",
       "           -0.03841073,  0.10989591,  0.06390093,  0.09982163,\n",
       "           -0.02210791,  0.0941402 ,  0.13105945, -0.09381908],\n",
       "          [ 0.01755702,  0.04506248,  0.07340768, -0.09435928,\n",
       "           -0.07162756,  0.04786131, -0.10149066,  0.00102404,\n",
       "            0.12744264, -0.09121285, -0.00406165,  0.06522262,\n",
       "           -0.02212805,  0.0194021 ,  0.01564209, -0.09416965,\n",
       "           -0.04782489, -0.05909103, -0.08518016, -0.05175482,\n",
       "           -0.08934779, -0.06365208, -0.05568346,  0.11291738,\n",
       "            0.01213065, -0.12096423,  0.01822348,  0.08693896,\n",
       "            0.01928934,  0.12439074,  0.01610412, -0.1287185 ],\n",
       "          [-0.07020281,  0.02190445,  0.13197295, -0.10043707,\n",
       "           -0.12156017, -0.09001803, -0.08638258, -0.0607499 ,\n",
       "           -0.06073199, -0.03302275, -0.0369337 , -0.10211542,\n",
       "           -0.07935534, -0.05918194,  0.01489475,  0.08837329,\n",
       "           -0.02246789, -0.10758326,  0.07691064, -0.03442783,\n",
       "            0.09125786,  0.13309805, -0.06160154, -0.06786133,\n",
       "            0.10856235,  0.05318424,  0.10483794,  0.01538169,\n",
       "            0.08893076,  0.01801763,  0.01747286,  0.05290632]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03690448, -0.09307536, -0.01820266, -0.08406331,\n",
       "            0.10517314,  0.09632705, -0.12208027, -0.12146264,\n",
       "            0.08652933, -0.12267108,  0.0077187 ,  0.12649511,\n",
       "           -0.09258235,  0.00087649, -0.06548264,  0.01197892,\n",
       "            0.00031161, -0.01846007, -0.01158574, -0.07846174,\n",
       "           -0.06326748,  0.05336344,  0.12755604,  0.13032745,\n",
       "           -0.11218067, -0.05757767, -0.07233252, -0.02204575,\n",
       "           -0.03183476,  0.12089549,  0.08854713, -0.1189875 ],\n",
       "          [ 0.10090736, -0.04765987, -0.00342984, -0.0058085 ,\n",
       "           -0.04320408,  0.12136419, -0.12185641,  0.06416914,\n",
       "           -0.13506752, -0.0529415 ,  0.13787837,  0.02129816,\n",
       "            0.10874932, -0.1331525 ,  0.01936781,  0.01306982,\n",
       "            0.01267467,  0.06312819,  0.07936142,  0.08824782,\n",
       "           -0.12335125, -0.00829707, -0.01102531, -0.12644859,\n",
       "            0.10148285, -0.07649274,  0.1267323 ,  0.01941626,\n",
       "            0.01975533,  0.08299729, -0.08374058,  0.02894422],\n",
       "          [ 0.11587332,  0.07617722, -0.12710142, -0.03741915,\n",
       "           -0.07699849,  0.11546932, -0.10314699,  0.01607236,\n",
       "            0.10763364,  0.13749127,  0.03161749,  0.01103228,\n",
       "           -0.11221893,  0.07927169, -0.07636313, -0.06739774,\n",
       "            0.01305245, -0.0213349 ,  0.03879543, -0.10949632,\n",
       "           -0.12825987, -0.05388083,  0.0719593 , -0.05399505,\n",
       "            0.07831459, -0.0601838 ,  0.0978978 , -0.02527796,\n",
       "            0.13328235, -0.06159009,  0.03656861,  0.11589004]],\n",
       " \n",
       "         [[ 0.01743397,  0.12029333,  0.09796523, -0.07164612,\n",
       "            0.01579365,  0.07169271, -0.1331672 , -0.12193614,\n",
       "            0.04599449, -0.05730285,  0.07429865,  0.01596585,\n",
       "            0.02321026, -0.02331486,  0.07096466, -0.11568207,\n",
       "           -0.10520299, -0.03715656,  0.06824237,  0.0810868 ,\n",
       "           -0.02529606,  0.08791605, -0.07835013,  0.02624379,\n",
       "            0.04243109, -0.04282597,  0.07052298, -0.06341489,\n",
       "            0.09854183,  0.0307198 , -0.10910188, -0.12602593],\n",
       "          [ 0.11135489, -0.04582299,  0.03430703, -0.05896536,\n",
       "           -0.08683991,  0.00445022, -0.10804426,  0.04778185,\n",
       "           -0.04889229, -0.13691205, -0.00635578, -0.1306184 ,\n",
       "            0.09386893,  0.12943421, -0.11617025,  0.03441186,\n",
       "            0.04940484, -0.03862991, -0.07755229,  0.08860451,\n",
       "           -0.00037646,  0.00193392,  0.07627811, -0.09372451,\n",
       "            0.02795616, -0.05203454, -0.12154694,  0.09676407,\n",
       "           -0.0870209 , -0.00973247, -0.10923953,  0.04698864],\n",
       "          [ 0.00088531,  0.00054401,  0.12199976,  0.0300393 ,\n",
       "           -0.00346534,  0.04083845, -0.01899425, -0.04333419,\n",
       "            0.07882616,  0.04926263,  0.11273549, -0.0807302 ,\n",
       "            0.05578202, -0.07421273, -0.09654157,  0.10437602,\n",
       "            0.0228323 ,  0.12804042, -0.10453446, -0.07009284,\n",
       "            0.05667932, -0.05997992,  0.05155045, -0.01270816,\n",
       "            0.10654815,  0.10791434,  0.06714927, -0.05980263,\n",
       "           -0.03132111,  0.10453621,  0.10740265, -0.04536659]],\n",
       " \n",
       "         [[ 0.10711539,  0.06747128, -0.03724919, -0.03994045,\n",
       "            0.02839112,  0.04414806,  0.09152564, -0.10302573,\n",
       "           -0.03494493,  0.08635753, -0.05685093,  0.04034673,\n",
       "           -0.10614802, -0.10186423,  0.05014047, -0.04375975,\n",
       "            0.1230119 , -0.1256906 ,  0.07284494,  0.03129913,\n",
       "            0.12338369,  0.11813141,  0.10264598,  0.04915448,\n",
       "            0.02677359,  0.11845906,  0.04195841, -0.02090652,\n",
       "           -0.02403952, -0.12892629, -0.03649189, -0.12563142],\n",
       "          [ 0.08707742,  0.0144261 , -0.01026869, -0.00278415,\n",
       "           -0.0411016 ,  0.07045753, -0.10977235, -0.0045214 ,\n",
       "            0.1066965 ,  0.07005329, -0.07694009, -0.05699228,\n",
       "            0.06437825,  0.06182145, -0.04869539, -0.05937743,\n",
       "           -0.12303954, -0.12236887, -0.12145221,  0.029082  ,\n",
       "            0.10430518,  0.01320733, -0.07671956,  0.11091617,\n",
       "           -0.02406371,  0.09653255,  0.03563994, -0.114664  ,\n",
       "           -0.13761717, -0.00694129,  0.0240463 ,  0.09041366],\n",
       "          [ 0.01311293,  0.04219739, -0.10706481, -0.12111802,\n",
       "            0.05939464, -0.03242955,  0.13258485, -0.11579537,\n",
       "            0.03671001, -0.01537225,  0.06853247, -0.02167152,\n",
       "           -0.0507708 , -0.01224887,  0.08851987,  0.01734562,\n",
       "           -0.02963911, -0.10995429,  0.1185341 , -0.0160621 ,\n",
       "           -0.0403813 ,  0.13344659, -0.04735619,  0.07092787,\n",
       "            0.04327467,  0.07491881, -0.10245783, -0.0952715 ,\n",
       "            0.09351909,  0.06451809,  0.09510276, -0.00120629]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_32/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_33/kernel:0' shape=(3, 3, 32, 32) dtype=float32, numpy=\n",
       " array([[[[ 0.04657058, -0.0556499 ,  0.10013644, ...,  0.03769054,\n",
       "           -0.00270199,  0.0889481 ],\n",
       "          [-0.06968108,  0.09212925, -0.01799299, ...,  0.03207874,\n",
       "            0.0502191 , -0.02293313],\n",
       "          [-0.09050485, -0.09210442, -0.1006921 , ..., -0.06811843,\n",
       "           -0.07755068, -0.00247078],\n",
       "          ...,\n",
       "          [-0.07127811,  0.02328487, -0.0145043 , ...,  0.05038632,\n",
       "           -0.0172167 , -0.00950167],\n",
       "          [-0.02072554,  0.09532484,  0.08542171, ..., -0.01019929,\n",
       "           -0.10004301,  0.00725586],\n",
       "          [-0.06268296,  0.05592486,  0.03306416, ...,  0.03283234,\n",
       "           -0.01690591, -0.05504436]],\n",
       " \n",
       "         [[-0.05380082,  0.07875615,  0.09484148, ...,  0.01661267,\n",
       "            0.05135141,  0.04218009],\n",
       "          [-0.02413503,  0.06914946, -0.09657862, ..., -0.06400327,\n",
       "            0.005952  , -0.08811164],\n",
       "          [ 0.05781731,  0.09852734, -0.04522001, ..., -0.05626196,\n",
       "           -0.07892859, -0.07846944],\n",
       "          ...,\n",
       "          [ 0.07351743, -0.04952019,  0.00087813, ...,  0.01519182,\n",
       "            0.02026355,  0.04859443],\n",
       "          [-0.00857473,  0.02149376, -0.04682704, ..., -0.06702851,\n",
       "           -0.05824268, -0.01409647],\n",
       "          [ 0.09444669, -0.04091991,  0.07453498, ...,  0.04212172,\n",
       "            0.03924374, -0.07802292]],\n",
       " \n",
       "         [[ 0.0116502 , -0.01386486,  0.08998339, ..., -0.09727967,\n",
       "           -0.09272128,  0.00415278],\n",
       "          [ 0.07999481,  0.06140329, -0.06221053, ...,  0.044531  ,\n",
       "            0.09630139, -0.00580191],\n",
       "          [ 0.0402925 , -0.04622298, -0.00108238, ...,  0.0203476 ,\n",
       "           -0.1000212 ,  0.06450821],\n",
       "          ...,\n",
       "          [-0.08972169, -0.03733344, -0.09576335, ...,  0.08501123,\n",
       "            0.051477  , -0.00178228],\n",
       "          [-0.00110019,  0.06116064, -0.07264152, ...,  0.03346118,\n",
       "            0.0838909 ,  0.09350997],\n",
       "          [-0.05753477,  0.04255232,  0.02162542, ..., -0.07792126,\n",
       "            0.03800653, -0.02827469]]],\n",
       " \n",
       " \n",
       "        [[[-0.00257631,  0.07259625, -0.09741387, ...,  0.09682801,\n",
       "           -0.10026784,  0.0591418 ],\n",
       "          [-0.09192874, -0.08131918, -0.02464312, ...,  0.08219035,\n",
       "           -0.02456287, -0.04516993],\n",
       "          [-0.08622859, -0.07762378,  0.09628232, ..., -0.04809968,\n",
       "           -0.04503004,  0.03323425],\n",
       "          ...,\n",
       "          [ 0.00863608, -0.07396232, -0.03092094, ..., -0.03846581,\n",
       "            0.04899162,  0.02434756],\n",
       "          [-0.10057659, -0.02118701, -0.03634144, ..., -0.00144763,\n",
       "           -0.02621579,  0.05356197],\n",
       "          [ 0.03059775,  0.06579629, -0.03164576, ...,  0.09673844,\n",
       "           -0.00462568, -0.01049085]],\n",
       " \n",
       "         [[ 0.04450355, -0.01510448,  0.06930649, ..., -0.07194415,\n",
       "           -0.0358481 , -0.01725002],\n",
       "          [-0.06377532,  0.07381634, -0.01519322, ...,  0.100337  ,\n",
       "           -0.03421351, -0.0364482 ],\n",
       "          [-0.05236636, -0.00043479, -0.09882348, ..., -0.05629172,\n",
       "           -0.06073514,  0.04690759],\n",
       "          ...,\n",
       "          [-0.07289089,  0.00450474,  0.06648485, ...,  0.02343129,\n",
       "           -0.01491629,  0.04127617],\n",
       "          [-0.0391067 ,  0.05680218,  0.0884589 , ...,  0.04627307,\n",
       "            0.04461789, -0.04708704],\n",
       "          [-0.01978365, -0.06951834,  0.04259999, ...,  0.01648473,\n",
       "            0.0633129 , -0.08036507]],\n",
       " \n",
       "         [[-0.01645046, -0.00995362,  0.05835989, ...,  0.02058882,\n",
       "           -0.04906669,  0.01978496],\n",
       "          [ 0.07637225, -0.03384504,  0.02548243, ...,  0.0376035 ,\n",
       "            0.04686509,  0.07834224],\n",
       "          [-0.04493757,  0.09943707, -0.03274782, ...,  0.02970272,\n",
       "           -0.03217465,  0.03143236],\n",
       "          ...,\n",
       "          [ 0.09398462, -0.08177549,  0.0861927 , ..., -0.07524973,\n",
       "           -0.02141107,  0.05560002],\n",
       "          [-0.07749259, -0.06914692,  0.04707029, ...,  0.03240846,\n",
       "           -0.01656208,  0.01737317],\n",
       "          [-0.05196109, -0.06950522,  0.07636118, ..., -0.02811278,\n",
       "            0.07242407, -0.04377046]]],\n",
       " \n",
       " \n",
       "        [[[ 0.04582819, -0.08785662, -0.00255032, ..., -0.08027885,\n",
       "            0.0367334 ,  0.0901189 ],\n",
       "          [ 0.01152738, -0.01539656,  0.08900788, ..., -0.04081299,\n",
       "           -0.02236474, -0.04365497],\n",
       "          [ 0.0762704 ,  0.07038683, -0.03501549, ..., -0.03021105,\n",
       "            0.0128166 ,  0.03222884],\n",
       "          ...,\n",
       "          [-0.07547187,  0.02956989, -0.03677205, ...,  0.09270641,\n",
       "           -0.0801211 ,  0.01874349],\n",
       "          [ 0.02765103,  0.0646465 ,  0.05012907, ...,  0.05507943,\n",
       "            0.01006144,  0.04676145],\n",
       "          [ 0.06935127, -0.06270812,  0.02314998, ..., -0.03832859,\n",
       "           -0.09319344, -0.00768019]],\n",
       " \n",
       "         [[-0.01695665,  0.05576646,  0.09816137, ..., -0.09121031,\n",
       "           -0.05126851, -0.02606526],\n",
       "          [-0.0705855 , -0.06528404, -0.0021588 , ...,  0.02872571,\n",
       "            0.01286468, -0.0304797 ],\n",
       "          [-0.09166099, -0.09445533, -0.08291539, ...,  0.09788021,\n",
       "            0.06098135,  0.03311543],\n",
       "          ...,\n",
       "          [-0.01891333,  0.00244819,  0.04422574, ...,  0.08175585,\n",
       "            0.04384319, -0.00475844],\n",
       "          [ 0.02876365,  0.06259592, -0.01342411, ..., -0.07512119,\n",
       "            0.05511142, -0.0763105 ],\n",
       "          [ 0.08780666, -0.08242066, -0.00095555, ...,  0.10046329,\n",
       "           -0.03193925, -0.03362942]],\n",
       " \n",
       "         [[ 0.01429914,  0.07626745, -0.04165607, ..., -0.02601579,\n",
       "           -0.06230548,  0.07137629],\n",
       "          [ 0.08074939, -0.09826975,  0.06995177, ..., -0.01500559,\n",
       "           -0.01305585, -0.00578889],\n",
       "          [-0.08186951, -0.07258898,  0.03347163, ...,  0.05554017,\n",
       "            0.07995038, -0.02517096],\n",
       "          ...,\n",
       "          [ 0.0347373 , -0.03100141, -0.04444457, ..., -0.02873491,\n",
       "            0.01748342,  0.01084213],\n",
       "          [-0.08519405, -0.03603014, -0.04678117, ..., -0.01290923,\n",
       "            0.00364399,  0.03807963],\n",
       "          [-0.10135607, -0.03878099,  0.08046663, ...,  0.06478114,\n",
       "            0.01436997, -0.05615769]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_33/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_34/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
       " array([[[[ 0.02508587, -0.02824571,  0.00981043, ...,  0.04867405,\n",
       "           -0.05761548, -0.00220597],\n",
       "          [ 0.07026573, -0.07636541,  0.00953013, ...,  0.07294027,\n",
       "            0.03948822,  0.03199055],\n",
       "          [-0.05340505, -0.01996845, -0.07010921, ..., -0.02834984,\n",
       "           -0.0478014 ,  0.00255194],\n",
       "          ...,\n",
       "          [-0.01699547, -0.07356872, -0.05636857, ..., -0.01717176,\n",
       "           -0.0530117 , -0.0659176 ],\n",
       "          [ 0.06762203,  0.05859364,  0.04654219, ...,  0.07090332,\n",
       "            0.03295586, -0.04015527],\n",
       "          [ 0.04364953, -0.03230935,  0.00561865, ...,  0.0050475 ,\n",
       "            0.0538323 ,  0.00571731]],\n",
       " \n",
       "         [[-0.0422552 ,  0.02157656,  0.0486742 , ..., -0.05621052,\n",
       "           -0.04915899, -0.05708003],\n",
       "          [-0.04533198, -0.0412344 , -0.02312921, ..., -0.03177577,\n",
       "            0.05763785, -0.01302888],\n",
       "          [-0.0792868 , -0.05043884,  0.01398516, ...,  0.0241892 ,\n",
       "           -0.04764485,  0.02894562],\n",
       "          ...,\n",
       "          [ 0.00539551,  0.06059393,  0.03096527, ...,  0.06527279,\n",
       "            0.02141011,  0.00560284],\n",
       "          [-0.00289705,  0.02347872, -0.06557237, ...,  0.05436099,\n",
       "           -0.029146  , -0.04082946],\n",
       "          [-0.04425287,  0.03911272, -0.00292846, ...,  0.04339195,\n",
       "           -0.01348776, -0.01961222]],\n",
       " \n",
       "         [[ 0.07100929, -0.05567771,  0.00015825, ..., -0.016997  ,\n",
       "            0.07502735,  0.05616543],\n",
       "          [-0.07519567, -0.07735258, -0.03725501, ..., -0.02013421,\n",
       "            0.05857775, -0.02417531],\n",
       "          [-0.01883582, -0.04467666, -0.00562016, ..., -0.06549256,\n",
       "           -0.06033081, -0.07037159],\n",
       "          ...,\n",
       "          [-0.0081479 ,  0.05568043,  0.03841314, ...,  0.01843228,\n",
       "            0.06234873,  0.0295855 ],\n",
       "          [-0.01280049, -0.06931417,  0.05968841, ..., -0.07573547,\n",
       "            0.06022841,  0.0281086 ],\n",
       "          [-0.07754628,  0.01236162,  0.04438957, ...,  0.05653048,\n",
       "            0.04533515, -0.06977242]]],\n",
       " \n",
       " \n",
       "        [[[-0.07602769, -0.0263115 ,  0.0198077 , ..., -0.04894783,\n",
       "            0.05332816,  0.00441563],\n",
       "          [ 0.03322599, -0.04949151, -0.03121108, ..., -0.02602603,\n",
       "           -0.06253916,  0.00780811],\n",
       "          [ 0.00219669,  0.07261346, -0.04847115, ...,  0.00102661,\n",
       "           -0.06195426, -0.08120444],\n",
       "          ...,\n",
       "          [ 0.07570604, -0.00379076, -0.03882587, ..., -0.07034986,\n",
       "           -0.01841837,  0.07655015],\n",
       "          [-0.06783293, -0.02890225, -0.06863108, ..., -0.07896721,\n",
       "           -0.01374014,  0.0573274 ],\n",
       "          [-0.08263785, -0.07228856,  0.06902941, ..., -0.08304562,\n",
       "            0.05503663, -0.04155137]],\n",
       " \n",
       "         [[-0.03831844, -0.02954237,  0.01965681, ..., -0.05222122,\n",
       "            0.01654474,  0.04363158],\n",
       "          [ 0.05359594, -0.0497453 , -0.04156031, ..., -0.06359051,\n",
       "           -0.02207325,  0.02378245],\n",
       "          [-0.07819915,  0.03169864, -0.06150995, ..., -0.04758926,\n",
       "            0.06416983, -0.05349706],\n",
       "          ...,\n",
       "          [ 0.01480535,  0.01237345,  0.07882283, ..., -0.05996146,\n",
       "           -0.07723453, -0.0170486 ],\n",
       "          [-0.02434425, -0.07395315,  0.07592017, ...,  0.01175161,\n",
       "           -0.00628457, -0.03611259],\n",
       "          [-0.07013144,  0.07351203, -0.01252488, ...,  0.08184753,\n",
       "           -0.07413449, -0.06097655]],\n",
       " \n",
       "         [[-0.06245792, -0.00460535, -0.0579345 , ...,  0.04330734,\n",
       "            0.02347934, -0.05647314],\n",
       "          [ 0.05763163, -0.00270089,  0.04581777, ...,  0.01397087,\n",
       "           -0.03046268,  0.07552888],\n",
       "          [-0.03612975, -0.06862273, -0.07919775, ...,  0.08258057,\n",
       "           -0.04198611, -0.01833753],\n",
       "          ...,\n",
       "          [-0.01347264,  0.07020114, -0.00793338, ...,  0.01460602,\n",
       "            0.00181359,  0.02170181],\n",
       "          [-0.00602774,  0.03285161, -0.08222672, ...,  0.06401537,\n",
       "           -0.04140165,  0.04261432],\n",
       "          [ 0.0109913 ,  0.05572505,  0.04875088, ..., -0.06095515,\n",
       "           -0.01833371,  0.06652511]]],\n",
       " \n",
       " \n",
       "        [[[ 0.05142816, -0.05628077, -0.050882  , ..., -0.0016158 ,\n",
       "           -0.02030579,  0.06906108],\n",
       "          [-0.05368124,  0.00112709,  0.06552697, ..., -0.02775351,\n",
       "           -0.0224633 ,  0.00015247],\n",
       "          [ 0.02509681, -0.00757297,  0.01562405, ..., -0.02154541,\n",
       "            0.05953784, -0.08188264],\n",
       "          ...,\n",
       "          [-0.08180215,  0.07627321, -0.08044668, ..., -0.06361789,\n",
       "           -0.06784277, -0.04011019],\n",
       "          [ 0.03460618, -0.00132225,  0.07308311, ...,  0.06567553,\n",
       "           -0.07566007,  0.06254277],\n",
       "          [-0.0547332 ,  0.07814857, -0.03729298, ..., -0.05409344,\n",
       "            0.0024334 , -0.0188209 ]],\n",
       " \n",
       "         [[-0.02161968, -0.03556508,  0.04933081, ..., -0.06369279,\n",
       "            0.04597082, -0.01036678],\n",
       "          [-0.06207876,  0.05691292,  0.07804903, ...,  0.01103721,\n",
       "           -0.03127859, -0.02630369],\n",
       "          [-0.05597814,  0.0761893 ,  0.06481964, ..., -0.02982271,\n",
       "            0.03848916,  0.01993388],\n",
       "          ...,\n",
       "          [ 0.01008099, -0.08277156, -0.03885567, ...,  0.08112998,\n",
       "            0.0667342 , -0.06717539],\n",
       "          [-0.07729304, -0.03996428,  0.01434245, ..., -0.02810965,\n",
       "           -0.01010541,  0.01112235],\n",
       "          [-0.03035816, -0.00698936, -0.06149856, ...,  0.07353463,\n",
       "            0.07379041,  0.01778177]],\n",
       " \n",
       "         [[-0.0302765 ,  0.0808774 , -0.05092569, ..., -0.07764976,\n",
       "            0.03662425,  0.0360413 ],\n",
       "          [ 0.05789801, -0.05541005,  0.05694432, ..., -0.01766763,\n",
       "            0.0323084 ,  0.05551883],\n",
       "          [-0.04135263,  0.00056585, -0.07516798, ...,  0.04493193,\n",
       "            0.02816043, -0.06611954],\n",
       "          ...,\n",
       "          [-0.06159931,  0.00845609, -0.04576707, ...,  0.07493592,\n",
       "           -0.00563729,  0.02298377],\n",
       "          [-0.06528559,  0.06674156,  0.03420905, ...,  0.06564815,\n",
       "            0.08321174, -0.04795792],\n",
       "          [ 0.00136163, -0.02101181,  0.07549735, ...,  0.05955609,\n",
       "           -0.05544569, -0.01147974]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_34/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_35/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[-0.0325878 , -0.06934343,  0.00848141, ..., -0.03948642,\n",
       "            0.02616285,  0.00670637],\n",
       "          [-0.04644119, -0.06297889, -0.02928921, ..., -0.02772989,\n",
       "           -0.062466  , -0.00859588],\n",
       "          [ 0.00773872, -0.03161035, -0.01741045, ...,  0.02084602,\n",
       "            0.00430297,  0.06426011],\n",
       "          ...,\n",
       "          [ 0.03605225,  0.03814852,  0.07179523, ..., -0.01750649,\n",
       "           -0.0407158 , -0.05427147],\n",
       "          [ 0.04689845, -0.02682874, -0.01904574, ..., -0.03665248,\n",
       "           -0.03633581,  0.05555324],\n",
       "          [ 0.00030151, -0.0720202 , -0.05024216, ...,  0.02267969,\n",
       "           -0.06831072, -0.06402266]],\n",
       " \n",
       "         [[ 0.04671615, -0.0560691 ,  0.01698008, ...,  0.05318964,\n",
       "           -0.02031309,  0.04531556],\n",
       "          [-0.06788205,  0.00580371, -0.04912356, ..., -0.04950604,\n",
       "            0.03967846,  0.01860884],\n",
       "          [-0.00688113,  0.00236566,  0.06462222, ..., -0.03860673,\n",
       "           -0.01314521,  0.05313814],\n",
       "          ...,\n",
       "          [ 0.05131032,  0.00035287, -0.04685909, ...,  0.04802364,\n",
       "           -0.03501889,  0.07145981],\n",
       "          [-0.0399498 , -0.06827697,  0.06587188, ..., -0.06216429,\n",
       "           -0.04360017,  0.02851351],\n",
       "          [ 0.0041567 ,  0.03813694, -0.05440753, ...,  0.04173006,\n",
       "           -0.05354878, -0.00665106]],\n",
       " \n",
       "         [[ 0.03897334,  0.04069433,  0.05613628, ..., -0.0286172 ,\n",
       "            0.02704977, -0.05219266],\n",
       "          [-0.05852521, -0.04572788,  0.02503325, ...,  0.02077409,\n",
       "           -0.05535562, -0.03636479],\n",
       "          [-0.00779822,  0.0113326 , -0.0344418 , ..., -0.07215489,\n",
       "           -0.00539422, -0.05248678],\n",
       "          ...,\n",
       "          [-0.03493258, -0.0204046 ,  0.07004988, ..., -0.03961366,\n",
       "           -0.07074728,  0.06887875],\n",
       "          [ 0.05397049,  0.01785229, -0.05294924, ..., -0.03105416,\n",
       "            0.05322446,  0.07181744],\n",
       "          [ 0.06019725,  0.02505853, -0.06758514, ..., -0.06088513,\n",
       "           -0.06353892, -0.07016452]]],\n",
       " \n",
       " \n",
       "        [[[-0.06384712, -0.05481333, -0.03968495, ...,  0.01225094,\n",
       "           -0.01345921,  0.02540926],\n",
       "          [-0.04167461,  0.02550349, -0.0672718 , ..., -0.03963766,\n",
       "           -0.01041057,  0.06594978],\n",
       "          [ 0.05783415, -0.00709558, -0.00233308, ..., -0.00878657,\n",
       "           -0.0517164 , -0.04979731],\n",
       "          ...,\n",
       "          [ 0.00994641, -0.00790464, -0.02673636, ..., -0.07124738,\n",
       "           -0.01336784,  0.07211004],\n",
       "          [ 0.01688097,  0.05786438,  0.02945402, ...,  0.01876588,\n",
       "            0.04403589, -0.06268524],\n",
       "          [-0.0139189 ,  0.06794859, -0.04843952, ...,  0.01474036,\n",
       "            0.01056033,  0.07126282]],\n",
       " \n",
       "         [[-0.01894746,  0.06046851, -0.04624414, ..., -0.04448326,\n",
       "           -0.07077631,  0.04980701],\n",
       "          [ 0.00917929,  0.06014614,  0.06594871, ...,  0.06880975,\n",
       "            0.02339338,  0.0245677 ],\n",
       "          [ 0.03272758,  0.03936403, -0.01399915, ...,  0.04288826,\n",
       "            0.07044263,  0.0711356 ],\n",
       "          ...,\n",
       "          [-0.02698389,  0.0171233 , -0.04022777, ...,  0.01470638,\n",
       "           -0.06393689, -0.001743  ],\n",
       "          [ 0.06759192, -0.01306584,  0.05739462, ...,  0.05442189,\n",
       "           -0.0372456 , -0.06145356],\n",
       "          [ 0.05555402,  0.05560286,  0.02457298, ..., -0.03143464,\n",
       "           -0.01960199,  0.04136679]],\n",
       " \n",
       "         [[-0.04288372,  0.02532383, -0.01656152, ..., -0.03991231,\n",
       "           -0.01295257,  0.00815567],\n",
       "          [-0.03393067,  0.0052412 ,  0.01259485, ..., -0.02599619,\n",
       "           -0.03748571, -0.01844913],\n",
       "          [-0.01707322,  0.06886974, -0.06385373, ..., -0.05686655,\n",
       "            0.04632238,  0.01674814],\n",
       "          ...,\n",
       "          [-0.04170425, -0.03053268,  0.05952542, ..., -0.06643562,\n",
       "           -0.02251733, -0.009446  ],\n",
       "          [ 0.02374281,  0.04640952, -0.04540065, ...,  0.02128961,\n",
       "           -0.0268717 , -0.06681949],\n",
       "          [ 0.06173557,  0.0653303 ,  0.05004136, ..., -0.05254966,\n",
       "            0.05710237, -0.01481516]]],\n",
       " \n",
       " \n",
       "        [[[-0.03317324, -0.06602225,  0.02882421, ..., -0.04225446,\n",
       "            0.01677539,  0.03255226],\n",
       "          [-0.02292745,  0.03548925,  0.02449677, ...,  0.01273456,\n",
       "            0.05619469, -0.05112506],\n",
       "          [-0.04642393, -0.02545362,  0.01373998, ...,  0.06368461,\n",
       "            0.06875053,  0.05587943],\n",
       "          ...,\n",
       "          [ 0.00273253, -0.04920283,  0.06611587, ...,  0.02179014,\n",
       "           -0.05465847, -0.00244379],\n",
       "          [ 0.02782463, -0.05199012, -0.06150528, ...,  0.00932667,\n",
       "           -0.04987264, -0.06911856],\n",
       "          [-0.05260112, -0.00504847,  0.00674891, ..., -0.03306696,\n",
       "           -0.04696748, -0.05031825]],\n",
       " \n",
       "         [[ 0.03693077,  0.0583232 , -0.02787562, ..., -0.04196679,\n",
       "            0.0336925 ,  0.04755446],\n",
       "          [-0.03310686, -0.05580292,  0.02330552, ...,  0.04577924,\n",
       "           -0.02318038,  0.0704219 ],\n",
       "          [-0.0149992 , -0.06516901,  0.00345091, ...,  0.01455557,\n",
       "            0.01586092, -0.02444423],\n",
       "          ...,\n",
       "          [ 0.0620541 ,  0.06370288, -0.0417048 , ...,  0.0340234 ,\n",
       "           -0.00584555,  0.06681484],\n",
       "          [-0.00509518,  0.02125762, -0.03187509, ..., -0.07153448,\n",
       "            0.01835356, -0.02406384],\n",
       "          [ 0.05712473,  0.00086766, -0.06951189, ..., -0.0641432 ,\n",
       "            0.02167107, -0.05458479]],\n",
       " \n",
       "         [[ 0.01004471, -0.02931236,  0.00884447, ..., -0.04383748,\n",
       "           -0.05432305,  0.06522913],\n",
       "          [-0.01185967, -0.02898413, -0.0072347 , ...,  0.0240033 ,\n",
       "           -0.00118089,  0.07021901],\n",
       "          [ 0.00086744, -0.06490307, -0.01256097, ..., -0.01978006,\n",
       "           -0.03744664, -0.01848561],\n",
       "          ...,\n",
       "          [ 0.06935324, -0.04077237,  0.0714673 , ...,  0.06817073,\n",
       "           -0.00605965,  0.00594269],\n",
       "          [ 0.02943442, -0.05696085,  0.01941604, ..., -0.03292446,\n",
       "            0.06471433,  0.04741611],\n",
       "          [-0.05417485, -0.05395249, -0.02719663, ...,  0.03921384,\n",
       "           -0.06738933,  0.02187884]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_35/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_25/kernel:0' shape=(179776, 64) dtype=float32, numpy=\n",
       " array([[-0.00458206, -0.00250549, -0.00075164, ..., -0.00568966,\n",
       "         -0.00417664,  0.00398199],\n",
       "        [-0.0034862 ,  0.00561752,  0.00573549, ...,  0.00334276,\n",
       "         -0.00282352,  0.00214895],\n",
       "        [ 0.00207283,  0.0057399 , -0.0018775 , ...,  0.0050008 ,\n",
       "         -0.00297385, -0.00534386],\n",
       "        ...,\n",
       "        [-0.00291527,  0.00191358,  0.00343117, ..., -0.00411733,\n",
       "         -0.00111603, -0.00577237],\n",
       "        [ 0.00061171, -0.00249866, -0.0045925 , ..., -0.00303194,\n",
       "         -0.00419119, -0.00152475],\n",
       "        [-0.00381551,  0.0056714 , -0.00292641, ..., -0.00157992,\n",
       "          0.00211244,  0.00151271]], dtype=float32)>,\n",
       " <tf.Variable 'dense_25/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_26/kernel:0' shape=(64, 4) dtype=float32, numpy=\n",
       " array([[ 0.0277164 , -0.22940269,  0.03162131,  0.16093457],\n",
       "        [ 0.11313882, -0.18936737, -0.28363886,  0.15045202],\n",
       "        [ 0.00518939,  0.08204144,  0.04805508,  0.11501005],\n",
       "        [-0.07536942, -0.16150197, -0.06578791, -0.22646052],\n",
       "        [-0.05555777,  0.12662092, -0.23844177,  0.1925548 ],\n",
       "        [ 0.20242956, -0.0189043 , -0.03868875, -0.09747049],\n",
       "        [ 0.18484122, -0.03666914, -0.10455853, -0.2160252 ],\n",
       "        [-0.14389265, -0.12763026, -0.02296311, -0.03575447],\n",
       "        [ 0.03958908, -0.1426178 ,  0.21765393, -0.18485254],\n",
       "        [ 0.20832157,  0.10966569, -0.09421854,  0.07758731],\n",
       "        [ 0.28245616, -0.12390289, -0.0323793 ,  0.2863505 ],\n",
       "        [ 0.00396922,  0.2443077 , -0.13356462, -0.28872496],\n",
       "        [-0.18009698,  0.1055457 ,  0.0926815 ,  0.11139911],\n",
       "        [ 0.19398403,  0.28305066, -0.24173112, -0.01566169],\n",
       "        [-0.01625991, -0.15756193, -0.13529457,  0.07313651],\n",
       "        [-0.12273102,  0.13738519, -0.21420029,  0.21910024],\n",
       "        [ 0.07514647,  0.2949792 , -0.08632477,  0.16276875],\n",
       "        [-0.2162521 , -0.2199423 ,  0.12085491,  0.13788924],\n",
       "        [-0.29608834,  0.0517464 , -0.22143003,  0.09468341],\n",
       "        [ 0.13620123,  0.18563426, -0.19094291, -0.16057783],\n",
       "        [-0.10609859,  0.14710933, -0.19817132, -0.11135577],\n",
       "        [ 0.20740014,  0.19642878, -0.02283514, -0.27469894],\n",
       "        [ 0.2678386 ,  0.05071718,  0.06184843,  0.09704188],\n",
       "        [-0.27044213,  0.01107767,  0.0100269 ,  0.2863297 ],\n",
       "        [-0.04804027,  0.2626753 ,  0.05321622, -0.05167183],\n",
       "        [ 0.29444373,  0.02896044,  0.00662303,  0.04276794],\n",
       "        [-0.2829833 , -0.05375318, -0.2918021 ,  0.23741704],\n",
       "        [-0.2877227 , -0.06824228, -0.06988788, -0.0711264 ],\n",
       "        [-0.21022815, -0.1314109 ,  0.19898406, -0.1542835 ],\n",
       "        [-0.09554473,  0.17884213, -0.00865805, -0.11556345],\n",
       "        [ 0.20549935,  0.0082126 , -0.19595441,  0.1584836 ],\n",
       "        [ 0.17669886, -0.2796969 , -0.02875546, -0.00210783],\n",
       "        [ 0.06124121, -0.13958766, -0.18790066, -0.02366275],\n",
       "        [ 0.28125793, -0.17379415, -0.16258405,  0.2744081 ],\n",
       "        [-0.29053923,  0.06900933,  0.07597643, -0.03561518],\n",
       "        [ 0.28872526,  0.12560636,  0.13288099, -0.2723697 ],\n",
       "        [ 0.21014935, -0.11013751, -0.11899805, -0.25119606],\n",
       "        [-0.00189525,  0.12898019,  0.09274858, -0.10136938],\n",
       "        [ 0.17306808, -0.06004669, -0.04855132, -0.00393695],\n",
       "        [-0.2779905 , -0.01026753, -0.03947747,  0.09030348],\n",
       "        [-0.04908134,  0.18843168, -0.26643246, -0.09182437],\n",
       "        [ 0.16816685, -0.05465779,  0.23661971,  0.24331105],\n",
       "        [-0.07827725,  0.17626294,  0.21238202,  0.17444733],\n",
       "        [ 0.28119683,  0.03953773,  0.0448314 ,  0.27992696],\n",
       "        [-0.25063515, -0.13677762, -0.04992425,  0.2712825 ],\n",
       "        [ 0.10350606,  0.2962646 , -0.28060073, -0.10282986],\n",
       "        [-0.16793902,  0.04074872,  0.12444147, -0.06833464],\n",
       "        [-0.15666853,  0.05698347, -0.0288972 ,  0.02691257],\n",
       "        [-0.16413198, -0.18036214, -0.18049678, -0.20413068],\n",
       "        [ 0.2916708 , -0.17602742,  0.16393086, -0.19111119],\n",
       "        [ 0.09757757, -0.24874714, -0.2348151 ,  0.08437514],\n",
       "        [ 0.02939272,  0.06398773,  0.01874012, -0.01013497],\n",
       "        [ 0.23586667,  0.07649264,  0.00877321,  0.09261382],\n",
       "        [-0.26068398, -0.1956853 , -0.24442054,  0.29055136],\n",
       "        [-0.15350963, -0.20411035, -0.1424887 ,  0.00987306],\n",
       "        [-0.08731328,  0.2414326 ,  0.19066778, -0.07055162],\n",
       "        [ 0.16631037,  0.19028357,  0.24759042,  0.14378756],\n",
       "        [-0.29300627, -0.22050901,  0.21795249,  0.02562803],\n",
       "        [-0.02430183,  0.05216128, -0.03376469, -0.12346479],\n",
       "        [-0.17003801, -0.04635587,  0.2620734 , -0.24043404],\n",
       "        [ 0.11086214,  0.0401271 ,  0.21134514,  0.04798567],\n",
       "        [ 0.16322923,  0.24099064,  0.2693131 , -0.16201699],\n",
       "        [ 0.27850443,  0.06423318, -0.04608011,  0.15517136],\n",
       "        [-0.03831354,  0.24764162,  0.12562782,  0.03348652]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_26/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.07678224,  0.09463818, -0.12440526,  0.11993076,\n",
       "            0.13325201,  0.1008423 ,  0.11898859,  0.00636776,\n",
       "            0.04068914, -0.02384677,  0.01979248,  0.05982994,\n",
       "           -0.02069925,  0.09641643,  0.02204329,  0.08712244,\n",
       "           -0.02213232,  0.118082  , -0.02963553,  0.06735153,\n",
       "           -0.01118872, -0.08326   ,  0.00621304, -0.12266005,\n",
       "           -0.08321426,  0.0273613 , -0.03178767, -0.09314308,\n",
       "            0.08756451,  0.13676934, -0.02963822, -0.08688299],\n",
       "          [ 0.02434   , -0.13766342, -0.02652779, -0.09675057,\n",
       "           -0.08460203, -0.11057214, -0.08729921,  0.03984269,\n",
       "           -0.12685484, -0.05976643, -0.08632496, -0.01598549,\n",
       "            0.06277286, -0.01991108, -0.01512282, -0.08341686,\n",
       "            0.02651992,  0.08315016, -0.01190893, -0.05064309,\n",
       "           -0.00458997, -0.10463008, -0.06552032, -0.00512192,\n",
       "           -0.09466967,  0.01916309, -0.11988015, -0.06785376,\n",
       "            0.04645592,  0.04443184, -0.04142933, -0.03349409],\n",
       "          [ 0.10782169,  0.01696582, -0.07012901,  0.05973418,\n",
       "           -0.10929228,  0.10911848,  0.09359549,  0.06347142,\n",
       "            0.06975412, -0.13520122,  0.08726771, -0.02483734,\n",
       "            0.11990254,  0.03723721, -0.04094086, -0.12418921,\n",
       "           -0.08682258,  0.06170657,  0.02803424, -0.05942389,\n",
       "           -0.04311232,  0.12195058, -0.07646718, -0.09703662,\n",
       "           -0.02984161, -0.01804093,  0.09932038, -0.11596072,\n",
       "           -0.05631287,  0.10741597,  0.05789779, -0.0304312 ]],\n",
       " \n",
       "         [[-0.04272203, -0.04832722, -0.01041795,  0.0683393 ,\n",
       "            0.01187913,  0.1188222 , -0.13230766,  0.05574803,\n",
       "           -0.12852728, -0.12229612,  0.03429434,  0.03769153,\n",
       "           -0.00583653,  0.00171177,  0.07400754, -0.13219965,\n",
       "            0.02533373,  0.0930194 ,  0.01505955, -0.1268905 ,\n",
       "            0.0978239 ,  0.10667032,  0.08115906,  0.10146746,\n",
       "            0.10020362, -0.09373964,  0.01622559,  0.07378681,\n",
       "            0.1360765 ,  0.05009654, -0.06225852,  0.00378828],\n",
       "          [ 0.06742646,  0.01328278, -0.03447643, -0.09153883,\n",
       "           -0.05825577,  0.10770126, -0.10084262, -0.06013662,\n",
       "            0.05474304, -0.06883574,  0.00393055,  0.05523328,\n",
       "           -0.07827922,  0.00324942,  0.0151203 , -0.10286252,\n",
       "            0.00390485,  0.00137433,  0.13401477, -0.04197088,\n",
       "           -0.11637515, -0.13395248,  0.05507499,  0.12770377,\n",
       "           -0.11547007,  0.00624537, -0.02293086,  0.03409667,\n",
       "           -0.00025374,  0.03627932,  0.11487286,  0.01043832],\n",
       "          [ 0.09564376,  0.01916227,  0.07437311,  0.00791655,\n",
       "            0.10115138, -0.07252409,  0.08001044,  0.1370575 ,\n",
       "           -0.13270509,  0.02276647, -0.09640679,  0.12127234,\n",
       "           -0.04684143,  0.07972786,  0.06012954,  0.10872772,\n",
       "            0.12428243, -0.13384679,  0.10533085, -0.06999258,\n",
       "            0.12956588, -0.05159645, -0.00048463, -0.0541522 ,\n",
       "            0.11245291, -0.05392555,  0.10339816, -0.0049763 ,\n",
       "            0.08900826, -0.03448886, -0.0141619 ,  0.04692672]],\n",
       " \n",
       "         [[-0.10715096,  0.03482361, -0.12652084,  0.057237  ,\n",
       "            0.01514095, -0.08278064,  0.05407146,  0.01985705,\n",
       "           -0.06669607,  0.03571552, -0.01642997, -0.0042782 ,\n",
       "           -0.12011473,  0.04226817,  0.08711764,  0.04182988,\n",
       "           -0.07341048,  0.03448689, -0.07949831,  0.12277339,\n",
       "            0.03726736,  0.04598787,  0.04095125, -0.04977451,\n",
       "           -0.0132025 , -0.01408099, -0.03594721,  0.06971592,\n",
       "            0.01043658,  0.04269183,  0.01545487, -0.09245968],\n",
       "          [-0.0811757 ,  0.13499768,  0.08428802,  0.02757637,\n",
       "            0.11979045,  0.07099289,  0.07897872,  0.08474039,\n",
       "            0.01857692,  0.13501163,  0.00309487,  0.02303825,\n",
       "            0.01912968,  0.04672623,  0.08546558, -0.05692832,\n",
       "            0.12209661,  0.09511876,  0.04526463,  0.03479919,\n",
       "            0.11943112,  0.04827219,  0.11694826, -0.03744481,\n",
       "           -0.13036013, -0.1018068 , -0.12251671,  0.11952044,\n",
       "           -0.00528219,  0.04167756, -0.04551322, -0.1273404 ],\n",
       "          [-0.01269135, -0.03261809,  0.05368835,  0.0033614 ,\n",
       "           -0.08215404,  0.09377722, -0.10609244, -0.03174585,\n",
       "            0.11857666,  0.1009267 ,  0.11935304, -0.07959673,\n",
       "            0.11872061,  0.08170554,  0.11835845, -0.03789722,\n",
       "           -0.1011342 ,  0.04837769,  0.09202501, -0.00238027,\n",
       "           -0.07222212, -0.06748415,  0.03193922, -0.10065603,\n",
       "            0.00943139, -0.01183832, -0.03346816, -0.03087706,\n",
       "            0.09040497, -0.09083928, -0.02625425, -0.05107787]]],\n",
       " \n",
       " \n",
       "        [[[-0.08709224,  0.02485383,  0.07953648, -0.00818367,\n",
       "            0.06382811,  0.07509267, -0.12523426, -0.12479841,\n",
       "           -0.10490826, -0.09033462,  0.11364491,  0.13418885,\n",
       "           -0.04064418,  0.1179121 , -0.12664342, -0.1077932 ,\n",
       "            0.03382798, -0.03305747, -0.01333342, -0.00379594,\n",
       "           -0.00904815,  0.08412845,  0.05631043, -0.05596164,\n",
       "           -0.10033865,  0.07998794, -0.05775654,  0.08700109,\n",
       "           -0.1336156 , -0.12510228, -0.08954197, -0.07143612],\n",
       "          [ 0.10677965,  0.10395424, -0.08381297,  0.04679246,\n",
       "            0.02089588,  0.09269384,  0.12106858,  0.10914275,\n",
       "            0.03203481, -0.0829473 , -0.06728767, -0.03627521,\n",
       "            0.01409961, -0.09792791,  0.02101184,  0.03185076,\n",
       "           -0.07612717,  0.0573142 , -0.0447926 , -0.00727758,\n",
       "            0.11450307,  0.12065111, -0.11007863, -0.04836246,\n",
       "           -0.08647787,  0.13370334,  0.05078031,  0.09177674,\n",
       "           -0.12356796,  0.05768506,  0.08885518, -0.11561716],\n",
       "          [ 0.06519356, -0.02588855, -0.12492259,  0.08162038,\n",
       "            0.05476496,  0.05425826, -0.05330418, -0.03134096,\n",
       "            0.10902308, -0.02814286, -0.06645188, -0.07812628,\n",
       "            0.13475631, -0.0939555 ,  0.10598691, -0.07944323,\n",
       "            0.06242976, -0.12744541,  0.05801919, -0.07815151,\n",
       "            0.10664491, -0.12058777,  0.02447627,  0.09193027,\n",
       "           -0.11735575,  0.07278526,  0.10174188, -0.13534452,\n",
       "           -0.05198074, -0.0068655 , -0.03451782, -0.1297827 ]],\n",
       " \n",
       "         [[-0.10784581,  0.05752568,  0.0630772 ,  0.11922221,\n",
       "            0.12293349,  0.12732257,  0.10506798, -0.11182915,\n",
       "            0.0952633 , -0.01039535,  0.03345966, -0.04766349,\n",
       "           -0.08282118, -0.05277263, -0.12727115,  0.11837806,\n",
       "            0.05549361, -0.10478941, -0.02278759,  0.00669038,\n",
       "            0.12253661, -0.05313399, -0.00231835,  0.13039728,\n",
       "           -0.06637193, -0.12352433, -0.01475817, -0.03521153,\n",
       "            0.0555065 , -0.09202372,  0.00630409, -0.0897063 ],\n",
       "          [ 0.12695278, -0.1002559 ,  0.03201692,  0.10607286,\n",
       "           -0.0362786 , -0.02126087,  0.01911044,  0.12546222,\n",
       "            0.03261098, -0.06316209, -0.04789708, -0.07687299,\n",
       "            0.10835341,  0.00424473, -0.02304632, -0.05261443,\n",
       "            0.09106342, -0.07554226,  0.06485961,  0.02688396,\n",
       "           -0.07027711,  0.07423609,  0.01924983,  0.03030393,\n",
       "            0.11215569, -0.07672265, -0.04320649,  0.0401523 ,\n",
       "           -0.03874462, -0.00265168,  0.03186138, -0.10117678],\n",
       "          [ 0.07849257, -0.0864656 , -0.13576284,  0.029479  ,\n",
       "           -0.01123281, -0.10249939,  0.00400235,  0.13635175,\n",
       "            0.0995845 , -0.05061022,  0.13428508,  0.02216299,\n",
       "            0.00250304,  0.02311946,  0.0529381 , -0.10714385,\n",
       "           -0.07772221,  0.07840274,  0.02332219, -0.00340049,\n",
       "           -0.05572055,  0.0906039 ,  0.03431112, -0.00039743,\n",
       "           -0.02800795,  0.1290129 , -0.10149013,  0.04700236,\n",
       "            0.05279392, -0.03023288, -0.06452606, -0.11341223]],\n",
       " \n",
       "         [[-0.0237877 , -0.08361544,  0.05352236, -0.10709199,\n",
       "            0.03577344, -0.06482477,  0.00604726,  0.11441936,\n",
       "            0.03915209,  0.05103746, -0.00279267, -0.08520734,\n",
       "            0.13452081,  0.08835207,  0.03350899, -0.04932696,\n",
       "            0.12356995,  0.04060335,  0.11643119, -0.08141729,\n",
       "           -0.09269169, -0.09059397,  0.13395758, -0.04303091,\n",
       "           -0.03841073,  0.10989591,  0.06390093,  0.09982163,\n",
       "           -0.02210791,  0.0941402 ,  0.13105945, -0.09381908],\n",
       "          [ 0.01755702,  0.04506248,  0.07340768, -0.09435928,\n",
       "           -0.07162756,  0.04786131, -0.10149066,  0.00102404,\n",
       "            0.12744264, -0.09121285, -0.00406165,  0.06522262,\n",
       "           -0.02212805,  0.0194021 ,  0.01564209, -0.09416965,\n",
       "           -0.04782489, -0.05909103, -0.08518016, -0.05175482,\n",
       "           -0.08934779, -0.06365208, -0.05568346,  0.11291738,\n",
       "            0.01213065, -0.12096423,  0.01822348,  0.08693896,\n",
       "            0.01928934,  0.12439074,  0.01610412, -0.1287185 ],\n",
       "          [-0.07020281,  0.02190445,  0.13197295, -0.10043707,\n",
       "           -0.12156017, -0.09001803, -0.08638258, -0.0607499 ,\n",
       "           -0.06073199, -0.03302275, -0.0369337 , -0.10211542,\n",
       "           -0.07935534, -0.05918194,  0.01489475,  0.08837329,\n",
       "           -0.02246789, -0.10758326,  0.07691064, -0.03442783,\n",
       "            0.09125786,  0.13309805, -0.06160154, -0.06786133,\n",
       "            0.10856235,  0.05318424,  0.10483794,  0.01538169,\n",
       "            0.08893076,  0.01801763,  0.01747286,  0.05290632]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03690448, -0.09307536, -0.01820266, -0.08406331,\n",
       "            0.10517314,  0.09632705, -0.12208027, -0.12146264,\n",
       "            0.08652933, -0.12267108,  0.0077187 ,  0.12649511,\n",
       "           -0.09258235,  0.00087649, -0.06548264,  0.01197892,\n",
       "            0.00031161, -0.01846007, -0.01158574, -0.07846174,\n",
       "           -0.06326748,  0.05336344,  0.12755604,  0.13032745,\n",
       "           -0.11218067, -0.05757767, -0.07233252, -0.02204575,\n",
       "           -0.03183476,  0.12089549,  0.08854713, -0.1189875 ],\n",
       "          [ 0.10090736, -0.04765987, -0.00342984, -0.0058085 ,\n",
       "           -0.04320408,  0.12136419, -0.12185641,  0.06416914,\n",
       "           -0.13506752, -0.0529415 ,  0.13787837,  0.02129816,\n",
       "            0.10874932, -0.1331525 ,  0.01936781,  0.01306982,\n",
       "            0.01267467,  0.06312819,  0.07936142,  0.08824782,\n",
       "           -0.12335125, -0.00829707, -0.01102531, -0.12644859,\n",
       "            0.10148285, -0.07649274,  0.1267323 ,  0.01941626,\n",
       "            0.01975533,  0.08299729, -0.08374058,  0.02894422],\n",
       "          [ 0.11587332,  0.07617722, -0.12710142, -0.03741915,\n",
       "           -0.07699849,  0.11546932, -0.10314699,  0.01607236,\n",
       "            0.10763364,  0.13749127,  0.03161749,  0.01103228,\n",
       "           -0.11221893,  0.07927169, -0.07636313, -0.06739774,\n",
       "            0.01305245, -0.0213349 ,  0.03879543, -0.10949632,\n",
       "           -0.12825987, -0.05388083,  0.0719593 , -0.05399505,\n",
       "            0.07831459, -0.0601838 ,  0.0978978 , -0.02527796,\n",
       "            0.13328235, -0.06159009,  0.03656861,  0.11589004]],\n",
       " \n",
       "         [[ 0.01743397,  0.12029333,  0.09796523, -0.07164612,\n",
       "            0.01579365,  0.07169271, -0.1331672 , -0.12193614,\n",
       "            0.04599449, -0.05730285,  0.07429865,  0.01596585,\n",
       "            0.02321026, -0.02331486,  0.07096466, -0.11568207,\n",
       "           -0.10520299, -0.03715656,  0.06824237,  0.0810868 ,\n",
       "           -0.02529606,  0.08791605, -0.07835013,  0.02624379,\n",
       "            0.04243109, -0.04282597,  0.07052298, -0.06341489,\n",
       "            0.09854183,  0.0307198 , -0.10910188, -0.12602593],\n",
       "          [ 0.11135489, -0.04582299,  0.03430703, -0.05896536,\n",
       "           -0.08683991,  0.00445022, -0.10804426,  0.04778185,\n",
       "           -0.04889229, -0.13691205, -0.00635578, -0.1306184 ,\n",
       "            0.09386893,  0.12943421, -0.11617025,  0.03441186,\n",
       "            0.04940484, -0.03862991, -0.07755229,  0.08860451,\n",
       "           -0.00037646,  0.00193392,  0.07627811, -0.09372451,\n",
       "            0.02795616, -0.05203454, -0.12154694,  0.09676407,\n",
       "           -0.0870209 , -0.00973247, -0.10923953,  0.04698864],\n",
       "          [ 0.00088531,  0.00054401,  0.12199976,  0.0300393 ,\n",
       "           -0.00346534,  0.04083845, -0.01899425, -0.04333419,\n",
       "            0.07882616,  0.04926263,  0.11273549, -0.0807302 ,\n",
       "            0.05578202, -0.07421273, -0.09654157,  0.10437602,\n",
       "            0.0228323 ,  0.12804042, -0.10453446, -0.07009284,\n",
       "            0.05667932, -0.05997992,  0.05155045, -0.01270816,\n",
       "            0.10654815,  0.10791434,  0.06714927, -0.05980263,\n",
       "           -0.03132111,  0.10453621,  0.10740265, -0.04536659]],\n",
       " \n",
       "         [[ 0.10711539,  0.06747128, -0.03724919, -0.03994045,\n",
       "            0.02839112,  0.04414806,  0.09152564, -0.10302573,\n",
       "           -0.03494493,  0.08635753, -0.05685093,  0.04034673,\n",
       "           -0.10614802, -0.10186423,  0.05014047, -0.04375975,\n",
       "            0.1230119 , -0.1256906 ,  0.07284494,  0.03129913,\n",
       "            0.12338369,  0.11813141,  0.10264598,  0.04915448,\n",
       "            0.02677359,  0.11845906,  0.04195841, -0.02090652,\n",
       "           -0.02403952, -0.12892629, -0.03649189, -0.12563142],\n",
       "          [ 0.08707742,  0.0144261 , -0.01026869, -0.00278415,\n",
       "           -0.0411016 ,  0.07045753, -0.10977235, -0.0045214 ,\n",
       "            0.1066965 ,  0.07005329, -0.07694009, -0.05699228,\n",
       "            0.06437825,  0.06182145, -0.04869539, -0.05937743,\n",
       "           -0.12303954, -0.12236887, -0.12145221,  0.029082  ,\n",
       "            0.10430518,  0.01320733, -0.07671956,  0.11091617,\n",
       "           -0.02406371,  0.09653255,  0.03563994, -0.114664  ,\n",
       "           -0.13761717, -0.00694129,  0.0240463 ,  0.09041366],\n",
       "          [ 0.01311293,  0.04219739, -0.10706481, -0.12111802,\n",
       "            0.05939464, -0.03242955,  0.13258485, -0.11579537,\n",
       "            0.03671001, -0.01537225,  0.06853247, -0.02167152,\n",
       "           -0.0507708 , -0.01224887,  0.08851987,  0.01734562,\n",
       "           -0.02963911, -0.10995429,  0.1185341 , -0.0160621 ,\n",
       "           -0.0403813 ,  0.13344659, -0.04735619,  0.07092787,\n",
       "            0.04327467,  0.07491881, -0.10245783, -0.0952715 ,\n",
       "            0.09351909,  0.06451809,  0.09510276, -0.00120629]]]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 646 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "646/646 [==============================] - 110s 170ms/step - loss: 2.7722 - accuracy: 0.2415 - val_loss: 1.3848 - val_accuracy: 0.3580\n",
      "Epoch 2/10\n",
      "646/646 [==============================] - 116s 180ms/step - loss: 1.3761 - accuracy: 0.3266 - val_loss: 1.3760 - val_accuracy: 0.3827\n",
      "Epoch 3/10\n",
      "646/646 [==============================] - 117s 180ms/step - loss: 1.3358 - accuracy: 0.3483 - val_loss: 1.3546 - val_accuracy: 0.3457\n",
      "Epoch 4/10\n",
      "646/646 [==============================] - 118s 183ms/step - loss: 1.4156 - accuracy: 0.3839 - val_loss: 1.3508 - val_accuracy: 0.3272\n",
      "Epoch 5/10\n",
      "646/646 [==============================] - 89s 137ms/step - loss: 1.2789 - accuracy: 0.4334 - val_loss: 1.2619 - val_accuracy: 0.4568\n",
      "Epoch 6/10\n",
      "646/646 [==============================] - 75s 116ms/step - loss: 1.1643 - accuracy: 0.4892 - val_loss: 1.7734 - val_accuracy: 0.2654\n",
      "Epoch 7/10\n",
      "646/646 [==============================] - 77s 120ms/step - loss: 1.1140 - accuracy: 0.5232 - val_loss: 1.1823 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "646/646 [==============================] - 75s 116ms/step - loss: 1.0126 - accuracy: 0.5743 - val_loss: 1.4667 - val_accuracy: 0.5309\n",
      "Epoch 9/10\n",
      "646/646 [==============================] - 75s 116ms/step - loss: 0.9873 - accuracy: 0.6192 - val_loss: 1.2627 - val_accuracy: 0.4877\n",
      "Epoch 10/10\n",
      "646/646 [==============================] - 76s 117ms/step - loss: 0.7700 - accuracy: 0.7012 - val_loss: 1.8066 - val_accuracy: 0.4877\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 22ms/step\n",
      "Test Loss: 1.8065856430265639\n",
      "Test Accuracy: 0.48765432834625244\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print('Test Loss:', score[0])\n",
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we have the probabilties of 4 classes in the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.11088949e-05 5.47355860e-02 9.45179641e-01 4.36867158e-05]\n",
      " [5.95648191e-04 4.38391864e-02 9.55432892e-01 1.32275789e-04]\n",
      " [1.42817244e-01 7.45351553e-01 9.39243734e-02 1.79068875e-02]\n",
      " [4.17812914e-01 5.69570899e-01 1.18788434e-02 7.37281574e-04]\n",
      " [1.75324923e-04 9.59588885e-01 3.55878957e-02 4.64782398e-03]\n",
      " [1.29060773e-02 4.50141102e-01 3.97319913e-01 1.39632851e-01]\n",
      " [1.01003304e-01 5.39184749e-01 1.43097118e-01 2.16714755e-01]\n",
      " [2.17148531e-02 8.78250420e-01 8.96961465e-02 1.03385728e-02]\n",
      " [1.98626440e-05 9.99979854e-01 6.93633737e-08 1.21929503e-07]\n",
      " [1.61362323e-03 7.88096339e-02 1.00048646e-01 8.19528103e-01]\n",
      " [1.06844679e-02 6.83375657e-01 3.01818341e-01 4.12143767e-03]\n",
      " [2.16934022e-05 4.71542851e-04 1.15864706e-04 9.99390841e-01]\n",
      " [5.17231598e-03 3.36894467e-02 9.52548325e-01 8.58996157e-03]\n",
      " [1.63296505e-03 3.97308208e-02 2.11850367e-03 9.56517756e-01]\n",
      " [8.19062255e-03 4.04059082e-01 5.78856766e-01 8.89354572e-03]\n",
      " [1.45525817e-04 3.29335295e-02 9.66689408e-01 2.31553058e-04]\n",
      " [4.82869595e-01 5.07507861e-01 1.46851060e-03 8.15404858e-03]\n",
      " [2.10432094e-02 4.62456614e-01 2.12666482e-01 3.03833634e-01]\n",
      " [1.59934732e-10 3.19510018e-09 1.19947110e-08 1.00000000e+00]\n",
      " [1.94573067e-02 2.86103994e-01 2.10577607e-01 4.83861059e-01]\n",
      " [3.15615139e-03 1.35482950e-02 1.59677723e-03 9.81698751e-01]\n",
      " [9.52531293e-04 1.03976294e-01 5.47974557e-02 8.40273738e-01]\n",
      " [7.37352239e-04 9.99140143e-01 1.22461453e-04 4.91665411e-08]\n",
      " [2.61729777e-01 5.80641270e-01 6.81585297e-02 8.94703865e-02]\n",
      " [1.42383948e-01 4.61626679e-01 9.86278336e-03 3.86126637e-01]\n",
      " [6.84563257e-03 9.87409234e-01 5.61074214e-03 1.34424859e-04]\n",
      " [6.96742063e-05 8.97050679e-01 8.25944394e-02 2.02851612e-02]\n",
      " [2.68255943e-04 7.39435852e-03 8.26243428e-04 9.91511166e-01]\n",
      " [2.91424781e-01 6.99461162e-01 5.65212173e-03 3.46194161e-03]\n",
      " [4.98124957e-03 5.03915846e-02 7.67379776e-02 8.67889166e-01]\n",
      " [7.20754382e-04 6.60448790e-01 3.38690907e-01 1.39404248e-04]\n",
      " [1.98428091e-02 2.45125011e-01 7.30237484e-01 4.79471916e-03]\n",
      " [9.75811508e-06 1.27916923e-03 9.98710871e-01 2.56394515e-07]\n",
      " [2.74462183e-03 5.03752418e-02 9.46787596e-01 9.25525746e-05]\n",
      " [8.16533417e-02 7.28855312e-01 1.88909292e-01 5.82029985e-04]\n",
      " [6.33864605e-04 7.60478724e-04 6.08236121e-04 9.97997344e-01]\n",
      " [7.03250407e-05 2.00155773e-04 5.19730558e-04 9.99209762e-01]\n",
      " [1.03267729e-02 1.86150923e-01 8.00227940e-01 3.29431077e-03]\n",
      " [1.33729736e-06 3.79869089e-05 8.22902730e-05 9.99878407e-01]\n",
      " [7.28814513e-04 4.21630770e-01 5.77091813e-01 5.48593001e-04]\n",
      " [1.05198415e-03 4.24215883e-01 5.51986992e-01 2.27451399e-02]\n",
      " [1.01182655e-01 7.78284431e-01 9.72918198e-02 2.32411083e-02]\n",
      " [7.09202280e-03 3.27157527e-01 6.53015137e-01 1.27353026e-02]\n",
      " [1.14513123e-02 7.69681811e-01 1.90761834e-01 2.81050317e-02]\n",
      " [2.62878746e-01 7.18005002e-01 4.19401145e-03 1.49221970e-02]\n",
      " [5.73901692e-03 8.77310812e-01 6.82002530e-02 4.87499498e-02]\n",
      " [3.78195720e-04 1.54487416e-01 6.89500153e-01 1.55634180e-01]\n",
      " [2.20426872e-01 7.75676787e-01 1.58639287e-03 2.30998266e-03]\n",
      " [2.89721005e-02 1.53523222e-01 8.17274213e-01 2.30434496e-04]\n",
      " [1.69489570e-02 5.36544979e-01 4.39783961e-01 6.72213547e-03]\n",
      " [1.24872457e-02 2.66935617e-01 7.19332218e-01 1.24496757e-03]\n",
      " [3.84474173e-02 4.30633947e-02 3.33708674e-02 8.85118306e-01]\n",
      " [4.12376458e-03 4.53242481e-01 2.17093349e-01 3.25540394e-01]\n",
      " [3.95301506e-02 7.35096872e-01 2.23290846e-01 2.08208896e-03]\n",
      " [1.27790850e-02 5.73971830e-02 9.26006615e-01 3.81708774e-03]\n",
      " [3.90169360e-02 1.43053934e-01 6.98802352e-01 1.19126745e-01]\n",
      " [8.33952129e-02 6.31381691e-01 2.60239422e-01 2.49837004e-02]\n",
      " [7.04417687e-07 2.01099768e-01 7.16207802e-01 8.26917961e-02]\n",
      " [9.48645611e-05 9.86988783e-01 1.21898344e-02 7.26505066e-04]\n",
      " [2.62459308e-01 3.52262646e-01 5.06169945e-02 3.34661007e-01]\n",
      " [2.22043111e-03 4.08507697e-02 1.73803158e-02 9.39548433e-01]\n",
      " [7.17290025e-03 1.11953564e-01 8.72432232e-01 8.44135508e-03]\n",
      " [5.35634645e-05 5.41159417e-03 1.12585956e-03 9.93409038e-01]\n",
      " [1.75931619e-03 3.96863818e-02 1.73454192e-02 9.41208899e-01]\n",
      " [5.68028372e-05 1.15184102e-03 3.44643788e-03 9.95344937e-01]\n",
      " [3.34979355e-01 3.41559023e-01 1.23256989e-01 2.00204656e-01]\n",
      " [4.99420916e-04 1.12705743e-02 7.81170232e-03 9.80418324e-01]\n",
      " [1.37351135e-05 3.20271938e-03 9.96780634e-01 2.84229964e-06]\n",
      " [1.35038748e-01 4.36291486e-01 3.36661981e-03 4.25303131e-01]\n",
      " [7.75109902e-02 2.30587184e-01 6.09153390e-01 8.27484727e-02]\n",
      " [5.50758792e-04 4.32885528e-01 5.66462219e-01 1.01444959e-04]\n",
      " [2.26234913e-01 4.63464856e-01 2.91990936e-01 1.83094367e-02]\n",
      " [2.19860375e-02 7.11606205e-01 1.60460874e-01 1.05946936e-01]\n",
      " [1.50599286e-01 3.11298281e-01 5.17168820e-01 2.09336691e-02]\n",
      " [1.80654007e-03 3.00835103e-01 6.93091810e-01 4.26660758e-03]\n",
      " [1.93684772e-02 8.91814530e-01 8.38229358e-02 4.99416469e-03]\n",
      " [1.20464996e-01 6.98048532e-01 1.78969741e-01 2.51674699e-03]\n",
      " [3.53729166e-03 9.25742537e-02 2.26860098e-03 9.01619852e-01]\n",
      " [1.96700782e-01 6.99976385e-01 7.91174322e-02 2.42053680e-02]\n",
      " [8.31893033e-07 1.16859592e-04 1.13511499e-06 9.99881148e-01]\n",
      " [1.36782425e-02 9.14825201e-02 6.84911609e-02 8.26348066e-01]\n",
      " [1.79149280e-03 3.23297501e-01 6.72138631e-01 2.77241576e-03]\n",
      " [8.90147989e-04 6.26213625e-02 1.70700799e-03 9.34781432e-01]\n",
      " [3.95913077e-07 6.28927955e-04 9.99370754e-01 1.49795678e-08]\n",
      " [6.92483084e-08 2.15966314e-01 7.84033656e-01 4.59006610e-09]\n",
      " [1.22561436e-02 7.49930084e-01 2.28021756e-01 9.79198143e-03]\n",
      " [1.25821307e-05 8.97031963e-01 8.54089037e-02 1.75465140e-02]\n",
      " [6.75963312e-02 1.78974226e-01 7.12719023e-01 4.07104790e-02]\n",
      " [3.57560143e-02 1.69634119e-01 7.45408773e-01 4.92011681e-02]\n",
      " [4.93508041e-01 4.76027906e-01 6.83692889e-03 2.36271862e-02]\n",
      " [6.67466811e-05 2.09623249e-03 9.74364758e-01 2.34723054e-02]\n",
      " [2.68039312e-05 7.96834171e-01 2.03103870e-01 3.51102026e-05]\n",
      " [3.76208544e-01 6.20789707e-01 2.11328181e-04 2.79033696e-03]\n",
      " [1.60257462e-02 5.97169459e-01 3.85515064e-01 1.28972484e-03]\n",
      " [8.36639199e-03 6.95531815e-02 2.45103668e-02 8.97570074e-01]\n",
      " [6.66919276e-02 4.68919665e-01 4.19153959e-01 4.52343635e-02]\n",
      " [9.85850953e-03 3.70278247e-02 9.47600007e-01 5.51367644e-03]\n",
      " [1.31363079e-01 6.68174505e-01 1.09354250e-01 9.11081880e-02]\n",
      " [1.57050563e-05 8.86322057e-04 9.99093771e-01 4.19868184e-06]\n",
      " [2.25827825e-05 7.14535825e-04 6.21154206e-03 9.93051410e-01]\n",
      " [3.40624712e-02 9.46764052e-01 1.36756506e-02 5.49777737e-03]\n",
      " [2.82662269e-02 3.65352005e-01 2.13262320e-01 3.93119454e-01]\n",
      " [6.61842003e-02 5.17499328e-01 4.09913749e-01 6.40267087e-03]\n",
      " [2.65549240e-03 4.45239097e-02 9.45014238e-01 7.80635141e-03]\n",
      " [9.37313363e-02 2.22378001e-01 1.18987083e-01 5.64903557e-01]\n",
      " [2.87597231e-05 6.08367473e-02 9.37600434e-01 1.53401517e-03]\n",
      " [4.34446603e-01 4.32364255e-01 1.04028434e-01 2.91607454e-02]\n",
      " [4.42472883e-05 3.28885838e-02 9.67065632e-01 1.46226535e-06]\n",
      " [3.07408180e-02 1.68248147e-01 7.89259911e-01 1.17511200e-02]\n",
      " [9.67428496e-04 2.21957728e-01 7.76955664e-01 1.19237811e-04]\n",
      " [3.42418738e-02 8.57508242e-01 7.95995817e-02 2.86503136e-02]\n",
      " [2.93257390e-03 1.31829292e-01 1.70802530e-02 8.48157883e-01]\n",
      " [2.43833493e-02 2.86367655e-01 6.88977301e-01 2.71714176e-04]\n",
      " [4.06522900e-02 8.53198647e-01 8.54370892e-02 2.07120255e-02]\n",
      " [2.99109016e-02 6.72959387e-01 3.90976705e-02 2.58032113e-01]\n",
      " [3.95651758e-01 4.61278558e-01 2.81941108e-02 1.14875585e-01]\n",
      " [4.08174354e-04 1.83175970e-03 3.81480320e-04 9.97378588e-01]\n",
      " [1.94260007e-04 4.59714346e-02 9.47875261e-01 5.95909962e-03]\n",
      " [1.06192462e-03 7.18759447e-02 2.00642482e-03 9.25055742e-01]\n",
      " [2.32600014e-05 4.18508789e-05 3.27387147e-06 9.99931574e-01]\n",
      " [4.57143560e-02 8.24412882e-01 1.24201372e-01 5.67145273e-03]\n",
      " [2.42890231e-03 2.28213985e-02 9.73044634e-01 1.70506036e-03]\n",
      " [5.06340882e-07 2.94495362e-06 1.48263507e-05 9.99981761e-01]\n",
      " [7.45994821e-02 9.25349414e-01 8.35196886e-07 5.01988434e-05]\n",
      " [1.45982066e-03 1.66954137e-02 9.81596887e-01 2.47929042e-04]\n",
      " [4.68854647e-04 9.83958244e-01 1.55710783e-02 1.84296778e-06]\n",
      " [4.34550494e-01 5.21123469e-01 2.40581911e-02 2.02677734e-02]\n",
      " [8.35393730e-04 2.14417949e-01 7.56391823e-01 2.83547807e-02]\n",
      " [3.39357406e-01 4.68517601e-01 4.02343199e-02 1.51890665e-01]\n",
      " [7.66026139e-01 2.33019754e-01 7.91150436e-04 1.62870434e-04]\n",
      " [3.01723555e-02 1.03387080e-01 8.59313905e-01 7.12664658e-03]\n",
      " [1.79001222e-06 1.33593625e-04 4.31217719e-04 9.99433339e-01]\n",
      " [3.85486963e-03 7.42711961e-01 2.35661209e-01 1.77718978e-02]\n",
      " [4.99153174e-02 9.22295928e-01 2.24826373e-02 5.30614518e-03]\n",
      " [3.66472686e-03 2.87318915e-01 2.36803293e-01 4.72213060e-01]\n",
      " [9.10450146e-03 1.53702408e-01 3.59121338e-02 8.01280975e-01]\n",
      " [4.19557182e-05 3.51136364e-03 3.45651130e-03 9.92990136e-01]\n",
      " [4.27461900e-02 4.37583834e-01 5.18019497e-01 1.65046519e-03]\n",
      " [8.52053054e-04 2.25350633e-01 4.71498724e-03 7.69082367e-01]\n",
      " [2.99133756e-03 8.15806568e-01 6.84614703e-02 1.12740651e-01]\n",
      " [4.71166894e-02 7.84104407e-01 1.65305167e-01 3.47369304e-03]\n",
      " [3.85055915e-02 3.07746887e-01 4.16268595e-02 6.12120628e-01]\n",
      " [8.14969651e-04 2.82743480e-02 3.70791629e-02 9.33831573e-01]\n",
      " [4.70349379e-02 6.33246720e-01 3.14269304e-01 5.44900354e-03]\n",
      " [4.11310612e-05 6.96467143e-03 8.46927799e-03 9.84524906e-01]\n",
      " [1.66231304e-01 3.56645525e-01 4.36373651e-01 4.07495052e-02]\n",
      " [1.77283268e-02 9.30077374e-01 5.15227169e-02 6.71608490e-04]\n",
      " [1.35981987e-04 9.95456815e-01 4.34356229e-03 6.35476899e-05]\n",
      " [9.00130981e-05 5.83110232e-05 1.42274046e-04 9.99709427e-01]\n",
      " [1.41161397e-01 8.14163923e-01 2.66977865e-02 1.79768484e-02]\n",
      " [5.14942668e-02 1.49925053e-01 7.71202147e-01 2.73785125e-02]\n",
      " [5.07742949e-02 1.73902974e-01 7.65802741e-01 9.52002686e-03]\n",
      " [6.41287118e-03 6.86013162e-01 3.04215312e-01 3.35864630e-03]\n",
      " [1.33729736e-06 3.79869089e-05 8.22902730e-05 9.99878407e-01]\n",
      " [9.24616412e-04 1.02830075e-01 1.65053412e-01 7.31191933e-01]\n",
      " [2.18546353e-02 8.39769423e-01 3.45435962e-02 1.03832386e-01]\n",
      " [7.34906970e-03 3.49615589e-02 1.76209621e-02 9.40068364e-01]\n",
      " [5.99637628e-04 2.64886841e-02 2.47747283e-02 9.48136866e-01]\n",
      " [1.86922979e-02 6.28876507e-01 3.97778526e-02 3.12653422e-01]\n",
      " [6.61008137e-09 6.78299833e-03 9.93216932e-01 1.01602184e-08]\n",
      " [3.41920386e-04 9.99657750e-01 3.20863990e-07 1.24781951e-09]\n",
      " [1.11214533e-01 5.62431037e-01 2.16791436e-01 1.09562911e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class with the high probablity in the output layer is label given by the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 1 1 1 1 1 1 3 1 3 2 3 2 2 1 1 3 3 3 3 1 1 1 1 1 3 1 3 1 2 2 2 1 3 3\n",
      " 2 3 2 2 1 2 1 1 1 2 1 2 1 2 3 1 1 2 2 1 2 1 1 3 2 3 3 3 1 3 2 1 2 2 1 1 2\n",
      " 2 1 1 3 1 3 3 2 3 2 2 1 1 2 2 0 2 1 1 1 3 1 2 1 2 3 1 3 1 2 3 2 0 2 2 2 1\n",
      " 3 2 1 1 1 3 2 3 3 1 2 3 1 2 1 1 2 1 0 2 3 1 1 3 3 3 2 3 1 1 3 3 1 3 2 1 1\n",
      " 3 1 2 2 1 3 3 1 3 3 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 31  4  3]\n",
      " [ 0 19 11 10]\n",
      " [ 0  5 27  1]\n",
      " [ 0 12  6 30]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving the weights and layer configuration of the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image agumentation ,creating image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20, #rotation ranges b/w 0 to 20\n",
    "    shear_range=0.5, \n",
    "    zoom_range=0.4, \n",
    "    vertical_flip=True, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we are not applying any agumentation on the test data as the model robustness should be maximized during the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving the images which are agumented by the image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_AUGMENTED = os.path.join(PATH , 'Train_Augmented_Images')\n",
    "TST_AUGMENTED = os.path.join(PATH , 'Test_Augmented_Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *FLOW* ......Takes data & label arrays, generates batches of augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_generator = train_data_gen.flow(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftest_generator = test_data_gen.flow(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        batch_size=batch_size, \n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fitting the agumented images and evaluating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(ftrain_generator, epochs = num_epoch, validation_data=ftest_generator,validation_steps=25,steps_per_epoch=X_train.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model_evaluate = model.evaluate_generator(ftest_generator, verbose=1, steps=X_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model_predict = model.predict_generator(ftest_generator, verbose=1,steps=X_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model_predict.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasfer learning--VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build top on top of the VGG16 we use functional  API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(img_rows, img_cols, num_channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the VGG with imagenet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(input_tensor=image_input, include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " include_top: whether to include the 3 fully-connected layers at the top of the network.\n",
    "\n",
    "weights: one of None (random initialization) or 'imagenet' (pre-training on ImageNet).\n",
    "\n",
    "input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = model.get_layer('fc2').output\n",
    "out = Dense(num_classes, activation='softmax', name='output')(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 134,276,932\n",
      "Trainable params: 134,276,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vgg_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_epoch=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model VGG.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "21/20 [===============================] - 217s 10s/step - loss: 2.0819 - accuracy: 0.3220 - val_loss: 1.1707 - val_accuracy: 0.4044\n",
      "Epoch 2/9\n",
      "21/20 [===============================] - 229s 11s/step - loss: 1.3716 - accuracy: 0.4040 - val_loss: 0.9781 - val_accuracy: 0.6118\n",
      "Epoch 3/9\n",
      "21/20 [===============================] - 222s 11s/step - loss: 1.2289 - accuracy: 0.4783 - val_loss: 0.7065 - val_accuracy: 0.6926\n",
      "Epoch 4/9\n",
      "21/20 [===============================] - 222s 11s/step - loss: 1.1563 - accuracy: 0.5279 - val_loss: 1.1629 - val_accuracy: 0.6368\n",
      "Epoch 5/9\n",
      "21/20 [===============================] - 233s 11s/step - loss: 1.1681 - accuracy: 0.5093 - val_loss: 0.9872 - val_accuracy: 0.6176\n",
      "Epoch 6/9\n",
      "21/20 [===============================] - 222s 11s/step - loss: 1.0351 - accuracy: 0.5681 - val_loss: 0.4208 - val_accuracy: 0.8031\n",
      "Epoch 7/9\n",
      "21/20 [===============================] - 230s 11s/step - loss: 1.1012 - accuracy: 0.5604 - val_loss: 0.4600 - val_accuracy: 0.6941\n",
      "Epoch 8/9\n",
      "21/20 [===============================] - 204s 10s/step - loss: 1.0646 - accuracy: 0.5604 - val_loss: 0.4293 - val_accuracy: 0.7015\n",
      "Epoch 9/9\n",
      "21/20 [===============================] - 204s 10s/step - loss: 1.0020 - accuracy: 0.6053 - val_loss: 0.6633 - val_accuracy: 0.6574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1da7a2cce80>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_vgg_model.fit_generator(ftrain_generator, epochs = Num_epoch, validation_data=ftest_generator,validation_steps=25,steps_per_epoch=X_train.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69285428e-04 5.76884905e-03 9.94008303e-01 5.35621548e-05]\n",
      " [9.16368049e-03 3.68106253e-02 9.51664209e-01 2.36153742e-03]\n",
      " [6.36741221e-02 7.43850052e-01 1.91626221e-01 8.49681208e-04]\n",
      " [2.53977120e-01 5.14868796e-01 2.20723346e-01 1.04307020e-02]\n",
      " [4.35439823e-03 6.58937693e-01 2.41861656e-01 9.48462635e-02]\n",
      " [7.92937633e-03 2.78308950e-02 9.58698273e-01 5.54152858e-03]\n",
      " [2.54746061e-03 9.55969915e-02 6.92997873e-01 2.08857715e-01]\n",
      " [3.26014496e-03 6.13350511e-01 8.14935565e-02 3.01895797e-01]\n",
      " [1.52806975e-02 9.45649266e-01 3.60467657e-02 3.02327774e-03]\n",
      " [5.50722843e-03 3.00024241e-01 6.07671082e-01 8.67974162e-02]\n",
      " [8.45628511e-03 9.35764372e-01 4.50397730e-02 1.07395751e-02]\n",
      " [1.79466943e-03 3.35684009e-02 8.81109852e-03 9.55825746e-01]\n",
      " [2.80715851e-03 1.97642446e-01 7.99285591e-01 2.64756556e-04]\n",
      " [2.35087820e-03 5.37705608e-02 1.76382557e-01 7.67496049e-01]\n",
      " [2.07872479e-03 1.11850649e-01 1.44399285e-01 7.41671324e-01]\n",
      " [5.59805194e-04 2.88881604e-02 9.69869375e-01 6.82645710e-04]\n",
      " [2.02170819e-01 7.12735474e-01 8.42621028e-02 8.31554644e-04]\n",
      " [1.73429996e-02 3.65646690e-01 2.08094075e-01 4.08916175e-01]\n",
      " [1.52552570e-03 1.34816999e-02 4.83376920e-01 5.01615822e-01]\n",
      " [5.99683039e-02 2.38821641e-01 6.90347195e-01 1.08629121e-02]\n",
      " [4.68178205e-02 4.97374386e-01 3.81740957e-01 7.40668476e-02]\n",
      " [2.30373669e-04 7.24896044e-03 1.14933483e-03 9.91371274e-01]\n",
      " [1.21057697e-01 8.16158593e-01 5.16500026e-02 1.11337341e-02]\n",
      " [4.76170808e-01 4.74496275e-01 4.81155142e-02 1.21733057e-03]\n",
      " [5.22578239e-01 3.88496637e-01 8.09273869e-02 7.99765345e-03]\n",
      " [2.67133825e-02 9.26355124e-01 4.04160395e-02 6.51551550e-03]\n",
      " [1.14691071e-03 4.29462418e-02 8.19486659e-03 9.47711945e-01]\n",
      " [8.57073974e-05 1.29000908e-02 7.28092641e-02 9.14204895e-01]\n",
      " [3.30791146e-01 6.43784165e-01 2.49282494e-02 4.96438704e-04]\n",
      " [4.80296090e-03 4.43843454e-02 4.65853550e-02 9.04227316e-01]\n",
      " [2.54174531e-03 5.83782196e-02 9.34658349e-01 4.42170678e-03]\n",
      " [2.50246935e-02 9.54712927e-01 2.01541260e-02 1.08186949e-04]\n",
      " [2.29130364e-05 8.47958727e-04 9.98866677e-01 2.62498303e-04]\n",
      " [1.11203026e-02 5.68397567e-02 9.27600026e-01 4.43999236e-03]\n",
      " [7.08773285e-02 1.93107873e-01 3.94954205e-01 3.41060519e-01]\n",
      " [1.24479202e-03 3.48474234e-02 1.46735653e-01 8.17172050e-01]\n",
      " [7.29548838e-03 1.54906258e-01 8.36755097e-01 1.04315602e-03]\n",
      " [1.78498833e-03 9.58214045e-01 3.97397876e-02 2.61115201e-04]\n",
      " [1.06538017e-03 9.42279026e-03 1.48461442e-02 9.74665642e-01]\n",
      " [5.09802339e-05 7.61959469e-04 9.98938859e-01 2.48185126e-04]\n",
      " [7.23530073e-03 8.65754843e-01 1.17981106e-01 9.02877003e-03]\n",
      " [1.42603204e-01 7.75770247e-01 8.02244022e-02 1.40210905e-03]\n",
      " [5.50759677e-03 8.92377555e-01 9.98687074e-02 2.24607950e-03]\n",
      " [3.34748685e-01 4.61008489e-01 1.99589163e-01 4.65376303e-03]\n",
      " [2.94856578e-02 9.03962553e-01 6.64229393e-02 1.28755681e-04]\n",
      " [5.08377841e-03 7.33200192e-01 2.61309206e-01 4.06785082e-04]\n",
      " [2.06650784e-05 1.26656583e-02 9.87266481e-01 4.71613093e-05]\n",
      " [4.87562984e-01 4.43320215e-01 6.74276054e-02 1.68915570e-03]\n",
      " [2.40504436e-04 2.23916676e-02 9.73224580e-01 4.14327066e-03]\n",
      " [5.33236206e-01 3.28238428e-01 1.31655976e-01 6.86937431e-03]\n",
      " [3.04816203e-04 7.84253981e-03 9.90426123e-01 1.42649305e-03]\n",
      " [6.70772940e-02 4.19696569e-01 6.57480136e-02 4.47478056e-01]\n",
      " [6.18523024e-02 6.68150783e-01 1.70894876e-01 9.91020873e-02]\n",
      " [4.40984266e-03 6.37988687e-01 3.57114136e-01 4.87371726e-04]\n",
      " [3.17137834e-04 3.44430818e-03 9.95386541e-01 8.51927849e-04]\n",
      " [2.36670226e-02 1.33937493e-01 8.11056435e-01 3.13390344e-02]\n",
      " [2.77707458e-01 6.62431300e-01 5.93705289e-02 4.90720209e-04]\n",
      " [3.00752610e-04 6.26905682e-03 9.92897511e-01 5.32675476e-04]\n",
      " [1.72762689e-03 1.22736529e-01 3.80036607e-02 8.37532222e-01]\n",
      " [4.44728822e-01 4.77533162e-01 7.32299164e-02 4.50810371e-03]\n",
      " [1.94162095e-03 3.32322381e-02 6.37688488e-02 9.01057243e-01]\n",
      " [2.75847882e-01 3.97687912e-01 3.21344644e-01 5.11947181e-03]\n",
      " [2.67846614e-01 3.71987164e-01 1.32627502e-01 2.27538690e-01]\n",
      " [1.62706291e-03 3.23702917e-02 5.02645411e-02 9.15738106e-01]\n",
      " [1.00891285e-01 7.60674953e-01 1.21243611e-01 1.71901062e-02]\n",
      " [2.01224655e-01 6.29394948e-01 1.63602918e-01 5.77750336e-03]\n",
      " [4.27177995e-02 7.04026520e-01 2.44113863e-01 9.14181583e-03]\n",
      " [1.23619111e-05 3.53532028e-03 9.96359289e-01 9.30453534e-05]\n",
      " [5.20840054e-03 1.19193740e-01 1.77944005e-02 8.57803404e-01]\n",
      " [9.83593892e-03 9.05762538e-02 8.98673952e-01 9.13940486e-04]\n",
      " [3.75849009e-01 4.05382097e-01 1.56053185e-01 6.27157092e-02]\n",
      " [4.07203645e-01 4.43462998e-01 1.16756409e-01 3.25769149e-02]\n",
      " [7.19141855e-04 2.01573148e-02 9.49130714e-01 2.99928226e-02]\n",
      " [2.06589878e-01 6.28172159e-01 6.53567016e-02 9.98812914e-02]\n",
      " [3.82098369e-04 2.47184858e-02 3.12200487e-01 6.62698865e-01]\n",
      " [4.69014615e-01 3.41011584e-01 1.84429124e-01 5.54463407e-03]\n",
      " [1.37499468e-02 8.54645312e-01 1.30988002e-01 6.16715755e-04]\n",
      " [8.72348342e-03 1.00589640e-01 1.68479562e-01 7.22207308e-01]\n",
      " [3.12897831e-01 6.64193630e-01 2.23017074e-02 6.06814981e-04]\n",
      " [3.92282428e-03 1.23152070e-01 8.62682819e-01 1.02422182e-02]\n",
      " [1.57755762e-02 6.23753846e-01 2.26396650e-01 1.34073928e-01]\n",
      " [4.65442536e-05 9.87169504e-01 1.27778333e-02 6.07856464e-06]\n",
      " [5.67355379e-02 9.03276801e-01 3.77921611e-02 2.19542510e-03]\n",
      " [1.09056188e-02 1.03586480e-01 7.65852034e-01 1.19655877e-01]\n",
      " [5.21585789e-05 2.09316713e-04 9.99677181e-01 6.14164019e-05]\n",
      " [4.67729941e-03 9.23214734e-01 7.16574714e-02 4.50590509e-04]\n",
      " [2.02599913e-04 3.82460713e-01 6.16265357e-01 1.07124459e-03]\n",
      " [8.10896512e-03 1.44824401e-01 6.56071231e-02 7.81459451e-01]\n",
      " [1.68609560e-01 7.77516186e-01 4.35473509e-02 1.03268735e-02]\n",
      " [8.35992396e-02 3.57650459e-01 5.03210127e-01 5.55401966e-02]\n",
      " [4.12269775e-03 8.34430456e-02 9.10688937e-01 1.74532470e-03]\n",
      " [8.03415460e-05 9.91424680e-01 8.28030985e-03 2.14622647e-04]\n",
      " [1.62492111e-01 6.41755581e-01 1.49407789e-01 4.63444889e-02]\n",
      " [6.92494094e-01 2.45377406e-01 5.82040884e-02 3.92443035e-03]\n",
      " [2.37924256e-03 1.31237842e-02 3.00262333e-03 9.81494308e-01]\n",
      " [2.03952968e-01 7.47578025e-01 4.64990102e-02 1.96997379e-03]\n",
      " [8.41360632e-03 1.68896560e-02 9.74149525e-01 5.47232397e-04]\n",
      " [6.16453472e-04 2.87484447e-03 9.96130705e-01 3.77935125e-04]\n",
      " [4.20294702e-04 1.00551099e-02 9.87867951e-01 1.65667327e-03]\n",
      " [7.97251705e-03 1.07950114e-01 1.57993641e-02 8.68277967e-01]\n",
      " [1.70862943e-01 6.48131549e-01 6.45978823e-02 1.16407566e-01]\n",
      " [2.91766226e-03 4.39654030e-02 9.03604507e-01 4.95123751e-02]\n",
      " [3.09222341e-01 5.96992254e-01 9.25140232e-02 1.27139466e-03]\n",
      " [1.26837417e-02 8.63974571e-01 9.91479307e-02 2.41937842e-02]\n",
      " [6.47994950e-02 5.36132634e-01 1.84324518e-01 2.14743361e-01]\n",
      " [1.32207060e-03 2.64467336e-02 5.39257424e-03 9.66838598e-01]\n",
      " [3.29960376e-01 4.03589070e-01 2.46887922e-01 1.95626821e-02]\n",
      " [1.18063192e-03 3.51310298e-02 6.07851483e-02 9.02903199e-01]\n",
      " [2.75985757e-03 1.34671077e-01 4.97348487e-01 3.65220487e-01]\n",
      " [4.00693789e-05 1.41326024e-03 9.98517931e-01 2.87136008e-05]\n",
      " [2.20635463e-03 5.78891393e-03 9.91781414e-01 2.23388633e-04]\n",
      " [6.87562628e-04 5.38979471e-02 7.60871321e-02 8.69327307e-01]\n",
      " [1.57620834e-05 1.95331313e-02 9.80397344e-01 5.37615160e-05]\n",
      " [3.12602073e-01 5.35903215e-01 1.25710830e-01 2.57837716e-02]\n",
      " [6.97999001e-02 6.16595261e-02 8.22598755e-01 4.59417738e-02]\n",
      " [4.21653315e-02 3.87203276e-01 5.60228705e-01 1.04027148e-02]\n",
      " [5.80530055e-03 3.88876572e-02 1.59410641e-01 7.95896411e-01]\n",
      " [2.61962507e-03 6.86430139e-03 9.62933660e-01 2.75825262e-02]\n",
      " [8.83715169e-04 9.23819765e-02 4.33923341e-02 8.63341987e-01]\n",
      " [1.93096363e-04 4.31535579e-02 5.68046212e-01 3.88607144e-01]\n",
      " [1.97567511e-04 4.14146557e-02 9.57004666e-01 1.38313661e-03]\n",
      " [6.45390078e-02 8.71626616e-01 5.55281341e-02 8.30623507e-03]\n",
      " [9.01513360e-03 1.10099256e-01 5.76422155e-01 3.04463387e-01]\n",
      " [1.69377044e-01 6.77354455e-01 1.02636069e-01 5.06324433e-02]\n",
      " [1.14724450e-02 3.52680795e-02 9.46673155e-01 6.58626808e-03]\n",
      " [1.63307879e-03 1.17803179e-02 9.83681440e-01 2.90516787e-03]\n",
      " [4.01735865e-02 8.19310188e-01 1.13854744e-01 2.66614798e-02]\n",
      " [2.89969641e-04 3.05243302e-03 9.83789206e-01 1.28683802e-02]\n",
      " [5.59770837e-02 9.04359221e-01 2.04691123e-02 1.91946812e-02]\n",
      " [3.20284694e-01 5.48547685e-01 9.90308300e-02 3.21368538e-02]\n",
      " [4.82338481e-02 1.51111126e-01 7.72837520e-01 2.78174654e-02]\n",
      " [1.02529721e-03 1.70117505e-02 1.21132797e-02 9.69849646e-01]\n",
      " [3.60798359e-01 4.83950317e-01 1.54514104e-01 7.37128605e-04]\n",
      " [8.60799700e-02 7.61519790e-01 1.45182610e-01 7.21753296e-03]\n",
      " [3.65251750e-02 4.36060935e-01 1.61628231e-01 3.65785658e-01]\n",
      " [1.11536816e-01 6.95759833e-01 5.45425788e-02 1.38160810e-01]\n",
      " [5.97021030e-03 6.28845811e-01 3.64480853e-01 7.03158788e-04]\n",
      " [7.43210403e-05 3.62050207e-03 9.95887458e-01 4.17819101e-04]\n",
      " [5.77170402e-02 8.98391366e-01 4.26079929e-02 1.28369732e-03]\n",
      " [6.50390936e-03 1.70003623e-01 1.33396789e-01 6.90095663e-01]\n",
      " [1.75590422e-02 9.59681869e-01 2.11920682e-02 1.56714104e-03]\n",
      " [5.91094673e-01 3.79278094e-01 2.90199872e-02 6.07241411e-04]\n",
      " [4.55378462e-03 3.05006772e-01 6.77376032e-01 1.30633842e-02]\n",
      " [2.91912700e-03 5.84223382e-02 6.91168904e-01 2.47489601e-01]\n",
      " [4.71873628e-03 5.15474260e-01 1.83741480e-01 2.96065480e-01]\n",
      " [3.97723109e-01 4.69123095e-01 1.14381440e-01 1.87722966e-02]\n",
      " [1.25595793e-01 6.19443774e-01 2.50858217e-01 4.10218397e-03]\n",
      " [4.53103363e-04 2.11517774e-02 1.45329125e-02 9.63862181e-01]\n",
      " [1.40549312e-03 4.08539027e-02 3.51196900e-02 9.22620952e-01]\n",
      " [1.02342814e-02 9.73046541e-01 1.25315627e-02 4.18770732e-03]\n",
      " [1.55002996e-01 7.60513484e-01 8.07369202e-02 3.74660525e-03]\n",
      " [6.91413460e-03 2.53462821e-01 7.37287283e-01 2.33572815e-03]\n",
      " [3.44235480e-01 6.29990458e-01 2.57651471e-02 8.86926591e-06]\n",
      " [1.06538017e-03 9.42279026e-03 1.48461442e-02 9.74665642e-01]\n",
      " [5.44726267e-04 1.41918724e-02 2.45159189e-03 9.82811749e-01]\n",
      " [1.14509240e-02 4.76210825e-02 9.62410048e-02 8.44686925e-01]\n",
      " [5.86679205e-04 2.15720851e-02 3.16166505e-02 9.46224570e-01]\n",
      " [5.53336777e-02 7.56570220e-01 1.83648199e-01 4.44790954e-03]\n",
      " [5.45610525e-02 5.70055902e-01 3.69588107e-01 5.79494750e-03]\n",
      " [4.86204820e-03 2.10897960e-02 9.72717166e-01 1.33093446e-03]\n",
      " [1.16061084e-02 9.81654525e-01 6.71764137e-03 2.15921118e-05]\n",
      " [1.77426577e-01 5.47735631e-01 5.23604378e-02 2.22477317e-01]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_VGG = custom_vgg_model.predict(X_test)\n",
    "print(Y_pred_VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 1 1 2 2 1 1 2 1 3 2 3 3 2 1 3 3 2 1 3 1 0 0 1 3 3 1 3 2 1 2 2 2 3 2\n",
      " 1 3 2 1 1 1 1 1 1 2 0 2 0 2 3 1 1 2 2 1 2 3 1 3 1 1 3 1 1 1 2 3 2 1 1 2 1\n",
      " 3 0 1 3 1 2 1 1 1 2 2 1 2 3 1 2 2 1 1 0 3 1 2 2 2 3 1 2 1 1 1 3 1 3 2 2 2\n",
      " 3 2 1 2 2 3 2 3 2 2 1 2 1 2 2 1 2 1 1 2 3 1 1 1 1 1 2 1 3 1 0 2 2 1 1 1 3\n",
      " 3 1 1 2 1 3 3 3 3 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_vgg = np.argmax(Y_pred_VGG, axis=1)\n",
    "print(y_pred_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 31  3  0]\n",
      " [ 0 33  7  0]\n",
      " [ 0  1 32  0]\n",
      " [ 0  4 10 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred_vgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/5 [===================================] - 25s 4s/step\n"
     ]
    }
   ],
   "source": [
    "vgg_model_evaluate = custom_vgg_model.evaluate_generator(ftest_generator, verbose=1, steps=X_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6498516798019409, 0.654321014881134]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/5 [===================================] - 24s 4s/step\n"
     ]
    }
   ],
   "source": [
    "VGG_model_predict = custom_vgg_model.predict_generator(ftest_generator, verbose=1,steps=X_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 2, 1, 3, 2, 2, 1, 1, 3, 1, 1, 1, 3, 2, 2, 1, 3, 1, 1, 3,\n",
       "       1, 1, 2, 2, 1, 3, 3, 2, 1, 1, 1, 2, 1, 2, 3, 2, 2, 3, 1, 3, 1, 1,\n",
       "       1, 3, 2, 1, 2, 3, 1, 2, 2, 1, 1, 1, 1, 0, 3, 1, 2, 2, 2, 2, 1, 1,\n",
       "       0, 1, 2, 2, 3, 1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 0, 2, 0,\n",
       "       3, 2, 3, 2, 3, 3, 3, 2, 1, 1, 3, 1, 1, 3, 2, 2, 1, 2, 1, 1, 1, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
       "       3, 2, 3, 3, 1, 0, 2, 3, 1, 1, 1, 3, 3, 3, 2, 3, 0, 3, 2, 1, 1, 2,\n",
       "       3, 1, 3, 1, 1, 2, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG_model_predict.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning--- ResNet50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(img_rows, img_cols, num_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "base_model = ResNet50(include_top=False, weights='imagenet',input_tensor=image_input,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing the low layers and enhancing the model with top level layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the output of the last convolution block in ResNet50\n",
    "x = base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Global Average Pooling layer\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fully connected layer having 1024 neurons\n",
    "x = Dense(1024, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fully connected layer having 4 neurons which will\n",
    "# give the probability of image having either dog or cat or human or horse\n",
    "predictions = Dense(4, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to be trained\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will try to train the last stage of ResNet50\n",
    "for layer in base_model.layers[0:143]:\n",
    "  layer.trainable = False\n",
    " \n",
    "for layer in base_model.layers[143:]:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 646 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "646/646 [==============================] - 216s 334ms/step - loss: 1.3583 - accuracy: 0.3282 - val_loss: 1.9071 - val_accuracy: 0.2037\n",
      "Epoch 2/10\n",
      "646/646 [==============================] - 216s 334ms/step - loss: 0.9360 - accuracy: 0.6950 - val_loss: 1.9025 - val_accuracy: 0.2037\n",
      "Epoch 3/10\n",
      "646/646 [==============================] - 220s 341ms/step - loss: 0.6411 - accuracy: 0.8638 - val_loss: 1.9114 - val_accuracy: 0.2037\n",
      "Epoch 4/10\n",
      "646/646 [==============================] - 219s 339ms/step - loss: 0.4804 - accuracy: 0.9226 - val_loss: 1.9074 - val_accuracy: 0.2037\n",
      "Epoch 5/10\n",
      "646/646 [==============================] - 213s 329ms/step - loss: 0.3748 - accuracy: 0.9427 - val_loss: 1.8799 - val_accuracy: 0.2037\n",
      "Epoch 6/10\n",
      "646/646 [==============================] - 221s 343ms/step - loss: 0.3082 - accuracy: 0.9567 - val_loss: 1.8756 - val_accuracy: 0.2037\n",
      "Epoch 7/10\n",
      "646/646 [==============================] - 224s 347ms/step - loss: 0.2633 - accuracy: 0.9675 - val_loss: 1.8921 - val_accuracy: 0.2037\n",
      "Epoch 8/10\n",
      "646/646 [==============================] - 236s 366ms/step - loss: 0.2280 - accuracy: 0.9721 - val_loss: 1.8831 - val_accuracy: 0.2037\n",
      "Epoch 9/10\n",
      "646/646 [==============================] - 223s 345ms/step - loss: 0.1953 - accuracy: 0.9814 - val_loss: 1.8887 - val_accuracy: 0.2037\n",
      "Epoch 10/10\n",
      "646/646 [==============================] - 211s 327ms/step - loss: 0.1809 - accuracy: 0.9830 - val_loss: 1.8778 - val_accuracy: 0.2037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1dac5fc7fd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69285428e-04 5.76884905e-03 9.94008303e-01 5.35621548e-05]\n",
      " [9.16368049e-03 3.68106253e-02 9.51664209e-01 2.36153742e-03]\n",
      " [6.36741221e-02 7.43850052e-01 1.91626221e-01 8.49681208e-04]\n",
      " [2.53977120e-01 5.14868796e-01 2.20723346e-01 1.04307020e-02]\n",
      " [4.35439823e-03 6.58937693e-01 2.41861656e-01 9.48462635e-02]\n",
      " [7.92937633e-03 2.78308950e-02 9.58698273e-01 5.54152858e-03]\n",
      " [2.54746061e-03 9.55969915e-02 6.92997873e-01 2.08857715e-01]\n",
      " [3.26014496e-03 6.13350511e-01 8.14935565e-02 3.01895797e-01]\n",
      " [1.52806975e-02 9.45649266e-01 3.60467657e-02 3.02327774e-03]\n",
      " [5.50722843e-03 3.00024241e-01 6.07671082e-01 8.67974162e-02]\n",
      " [8.45628511e-03 9.35764372e-01 4.50397730e-02 1.07395751e-02]\n",
      " [1.79466943e-03 3.35684009e-02 8.81109852e-03 9.55825746e-01]\n",
      " [2.80715851e-03 1.97642446e-01 7.99285591e-01 2.64756556e-04]\n",
      " [2.35087820e-03 5.37705608e-02 1.76382557e-01 7.67496049e-01]\n",
      " [2.07872479e-03 1.11850649e-01 1.44399285e-01 7.41671324e-01]\n",
      " [5.59805194e-04 2.88881604e-02 9.69869375e-01 6.82645710e-04]\n",
      " [2.02170819e-01 7.12735474e-01 8.42621028e-02 8.31554644e-04]\n",
      " [1.73429996e-02 3.65646690e-01 2.08094075e-01 4.08916175e-01]\n",
      " [1.52552570e-03 1.34816999e-02 4.83376920e-01 5.01615822e-01]\n",
      " [5.99683039e-02 2.38821641e-01 6.90347195e-01 1.08629121e-02]\n",
      " [4.68178205e-02 4.97374386e-01 3.81740957e-01 7.40668476e-02]\n",
      " [2.30373669e-04 7.24896044e-03 1.14933483e-03 9.91371274e-01]\n",
      " [1.21057697e-01 8.16158593e-01 5.16500026e-02 1.11337341e-02]\n",
      " [4.76170808e-01 4.74496275e-01 4.81155142e-02 1.21733057e-03]\n",
      " [5.22578239e-01 3.88496637e-01 8.09273869e-02 7.99765345e-03]\n",
      " [2.67133825e-02 9.26355124e-01 4.04160395e-02 6.51551550e-03]\n",
      " [1.14691071e-03 4.29462418e-02 8.19486659e-03 9.47711945e-01]\n",
      " [8.57073974e-05 1.29000908e-02 7.28092641e-02 9.14204895e-01]\n",
      " [3.30791146e-01 6.43784165e-01 2.49282494e-02 4.96438704e-04]\n",
      " [4.80296090e-03 4.43843454e-02 4.65853550e-02 9.04227316e-01]\n",
      " [2.54174531e-03 5.83782196e-02 9.34658349e-01 4.42170678e-03]\n",
      " [2.50246935e-02 9.54712927e-01 2.01541260e-02 1.08186949e-04]\n",
      " [2.29130364e-05 8.47958727e-04 9.98866677e-01 2.62498303e-04]\n",
      " [1.11203026e-02 5.68397567e-02 9.27600026e-01 4.43999236e-03]\n",
      " [7.08773285e-02 1.93107873e-01 3.94954205e-01 3.41060519e-01]\n",
      " [1.24479202e-03 3.48474234e-02 1.46735653e-01 8.17172050e-01]\n",
      " [7.29548838e-03 1.54906258e-01 8.36755097e-01 1.04315602e-03]\n",
      " [1.78498833e-03 9.58214045e-01 3.97397876e-02 2.61115201e-04]\n",
      " [1.06538017e-03 9.42279026e-03 1.48461442e-02 9.74665642e-01]\n",
      " [5.09802339e-05 7.61959469e-04 9.98938859e-01 2.48185126e-04]\n",
      " [7.23530073e-03 8.65754843e-01 1.17981106e-01 9.02877003e-03]\n",
      " [1.42603204e-01 7.75770247e-01 8.02244022e-02 1.40210905e-03]\n",
      " [5.50759677e-03 8.92377555e-01 9.98687074e-02 2.24607950e-03]\n",
      " [3.34748685e-01 4.61008489e-01 1.99589163e-01 4.65376303e-03]\n",
      " [2.94856578e-02 9.03962553e-01 6.64229393e-02 1.28755681e-04]\n",
      " [5.08377841e-03 7.33200192e-01 2.61309206e-01 4.06785082e-04]\n",
      " [2.06650784e-05 1.26656583e-02 9.87266481e-01 4.71613093e-05]\n",
      " [4.87562984e-01 4.43320215e-01 6.74276054e-02 1.68915570e-03]\n",
      " [2.40504436e-04 2.23916676e-02 9.73224580e-01 4.14327066e-03]\n",
      " [5.33236206e-01 3.28238428e-01 1.31655976e-01 6.86937431e-03]\n",
      " [3.04816203e-04 7.84253981e-03 9.90426123e-01 1.42649305e-03]\n",
      " [6.70772940e-02 4.19696569e-01 6.57480136e-02 4.47478056e-01]\n",
      " [6.18523024e-02 6.68150783e-01 1.70894876e-01 9.91020873e-02]\n",
      " [4.40984266e-03 6.37988687e-01 3.57114136e-01 4.87371726e-04]\n",
      " [3.17137834e-04 3.44430818e-03 9.95386541e-01 8.51927849e-04]\n",
      " [2.36670226e-02 1.33937493e-01 8.11056435e-01 3.13390344e-02]\n",
      " [2.77707458e-01 6.62431300e-01 5.93705289e-02 4.90720209e-04]\n",
      " [3.00752610e-04 6.26905682e-03 9.92897511e-01 5.32675476e-04]\n",
      " [1.72762689e-03 1.22736529e-01 3.80036607e-02 8.37532222e-01]\n",
      " [4.44728822e-01 4.77533162e-01 7.32299164e-02 4.50810371e-03]\n",
      " [1.94162095e-03 3.32322381e-02 6.37688488e-02 9.01057243e-01]\n",
      " [2.75847882e-01 3.97687912e-01 3.21344644e-01 5.11947181e-03]\n",
      " [2.67846614e-01 3.71987164e-01 1.32627502e-01 2.27538690e-01]\n",
      " [1.62706291e-03 3.23702917e-02 5.02645411e-02 9.15738106e-01]\n",
      " [1.00891285e-01 7.60674953e-01 1.21243611e-01 1.71901062e-02]\n",
      " [2.01224655e-01 6.29394948e-01 1.63602918e-01 5.77750336e-03]\n",
      " [4.27177995e-02 7.04026520e-01 2.44113863e-01 9.14181583e-03]\n",
      " [1.23619111e-05 3.53532028e-03 9.96359289e-01 9.30453534e-05]\n",
      " [5.20840054e-03 1.19193740e-01 1.77944005e-02 8.57803404e-01]\n",
      " [9.83593892e-03 9.05762538e-02 8.98673952e-01 9.13940486e-04]\n",
      " [3.75849009e-01 4.05382097e-01 1.56053185e-01 6.27157092e-02]\n",
      " [4.07203645e-01 4.43462998e-01 1.16756409e-01 3.25769149e-02]\n",
      " [7.19141855e-04 2.01573148e-02 9.49130714e-01 2.99928226e-02]\n",
      " [2.06589878e-01 6.28172159e-01 6.53567016e-02 9.98812914e-02]\n",
      " [3.82098369e-04 2.47184858e-02 3.12200487e-01 6.62698865e-01]\n",
      " [4.69014615e-01 3.41011584e-01 1.84429124e-01 5.54463407e-03]\n",
      " [1.37499468e-02 8.54645312e-01 1.30988002e-01 6.16715755e-04]\n",
      " [8.72348342e-03 1.00589640e-01 1.68479562e-01 7.22207308e-01]\n",
      " [3.12897831e-01 6.64193630e-01 2.23017074e-02 6.06814981e-04]\n",
      " [3.92282428e-03 1.23152070e-01 8.62682819e-01 1.02422182e-02]\n",
      " [1.57755762e-02 6.23753846e-01 2.26396650e-01 1.34073928e-01]\n",
      " [4.65442536e-05 9.87169504e-01 1.27778333e-02 6.07856464e-06]\n",
      " [5.67355379e-02 9.03276801e-01 3.77921611e-02 2.19542510e-03]\n",
      " [1.09056188e-02 1.03586480e-01 7.65852034e-01 1.19655877e-01]\n",
      " [5.21585789e-05 2.09316713e-04 9.99677181e-01 6.14164019e-05]\n",
      " [4.67729941e-03 9.23214734e-01 7.16574714e-02 4.50590509e-04]\n",
      " [2.02599913e-04 3.82460713e-01 6.16265357e-01 1.07124459e-03]\n",
      " [8.10896512e-03 1.44824401e-01 6.56071231e-02 7.81459451e-01]\n",
      " [1.68609560e-01 7.77516186e-01 4.35473509e-02 1.03268735e-02]\n",
      " [8.35992396e-02 3.57650459e-01 5.03210127e-01 5.55401966e-02]\n",
      " [4.12269775e-03 8.34430456e-02 9.10688937e-01 1.74532470e-03]\n",
      " [8.03415460e-05 9.91424680e-01 8.28030985e-03 2.14622647e-04]\n",
      " [1.62492111e-01 6.41755581e-01 1.49407789e-01 4.63444889e-02]\n",
      " [6.92494094e-01 2.45377406e-01 5.82040884e-02 3.92443035e-03]\n",
      " [2.37924256e-03 1.31237842e-02 3.00262333e-03 9.81494308e-01]\n",
      " [2.03952968e-01 7.47578025e-01 4.64990102e-02 1.96997379e-03]\n",
      " [8.41360632e-03 1.68896560e-02 9.74149525e-01 5.47232397e-04]\n",
      " [6.16453472e-04 2.87484447e-03 9.96130705e-01 3.77935125e-04]\n",
      " [4.20294702e-04 1.00551099e-02 9.87867951e-01 1.65667327e-03]\n",
      " [7.97251705e-03 1.07950114e-01 1.57993641e-02 8.68277967e-01]\n",
      " [1.70862943e-01 6.48131549e-01 6.45978823e-02 1.16407566e-01]\n",
      " [2.91766226e-03 4.39654030e-02 9.03604507e-01 4.95123751e-02]\n",
      " [3.09222341e-01 5.96992254e-01 9.25140232e-02 1.27139466e-03]\n",
      " [1.26837417e-02 8.63974571e-01 9.91479307e-02 2.41937842e-02]\n",
      " [6.47994950e-02 5.36132634e-01 1.84324518e-01 2.14743361e-01]\n",
      " [1.32207060e-03 2.64467336e-02 5.39257424e-03 9.66838598e-01]\n",
      " [3.29960376e-01 4.03589070e-01 2.46887922e-01 1.95626821e-02]\n",
      " [1.18063192e-03 3.51310298e-02 6.07851483e-02 9.02903199e-01]\n",
      " [2.75985757e-03 1.34671077e-01 4.97348487e-01 3.65220487e-01]\n",
      " [4.00693789e-05 1.41326024e-03 9.98517931e-01 2.87136008e-05]\n",
      " [2.20635463e-03 5.78891393e-03 9.91781414e-01 2.23388633e-04]\n",
      " [6.87562628e-04 5.38979471e-02 7.60871321e-02 8.69327307e-01]\n",
      " [1.57620834e-05 1.95331313e-02 9.80397344e-01 5.37615160e-05]\n",
      " [3.12602073e-01 5.35903215e-01 1.25710830e-01 2.57837716e-02]\n",
      " [6.97999001e-02 6.16595261e-02 8.22598755e-01 4.59417738e-02]\n",
      " [4.21653315e-02 3.87203276e-01 5.60228705e-01 1.04027148e-02]\n",
      " [5.80530055e-03 3.88876572e-02 1.59410641e-01 7.95896411e-01]\n",
      " [2.61962507e-03 6.86430139e-03 9.62933660e-01 2.75825262e-02]\n",
      " [8.83715169e-04 9.23819765e-02 4.33923341e-02 8.63341987e-01]\n",
      " [1.93096363e-04 4.31535579e-02 5.68046212e-01 3.88607144e-01]\n",
      " [1.97567511e-04 4.14146557e-02 9.57004666e-01 1.38313661e-03]\n",
      " [6.45390078e-02 8.71626616e-01 5.55281341e-02 8.30623507e-03]\n",
      " [9.01513360e-03 1.10099256e-01 5.76422155e-01 3.04463387e-01]\n",
      " [1.69377044e-01 6.77354455e-01 1.02636069e-01 5.06324433e-02]\n",
      " [1.14724450e-02 3.52680795e-02 9.46673155e-01 6.58626808e-03]\n",
      " [1.63307879e-03 1.17803179e-02 9.83681440e-01 2.90516787e-03]\n",
      " [4.01735865e-02 8.19310188e-01 1.13854744e-01 2.66614798e-02]\n",
      " [2.89969641e-04 3.05243302e-03 9.83789206e-01 1.28683802e-02]\n",
      " [5.59770837e-02 9.04359221e-01 2.04691123e-02 1.91946812e-02]\n",
      " [3.20284694e-01 5.48547685e-01 9.90308300e-02 3.21368538e-02]\n",
      " [4.82338481e-02 1.51111126e-01 7.72837520e-01 2.78174654e-02]\n",
      " [1.02529721e-03 1.70117505e-02 1.21132797e-02 9.69849646e-01]\n",
      " [3.60798359e-01 4.83950317e-01 1.54514104e-01 7.37128605e-04]\n",
      " [8.60799700e-02 7.61519790e-01 1.45182610e-01 7.21753296e-03]\n",
      " [3.65251750e-02 4.36060935e-01 1.61628231e-01 3.65785658e-01]\n",
      " [1.11536816e-01 6.95759833e-01 5.45425788e-02 1.38160810e-01]\n",
      " [5.97021030e-03 6.28845811e-01 3.64480853e-01 7.03158788e-04]\n",
      " [7.43210403e-05 3.62050207e-03 9.95887458e-01 4.17819101e-04]\n",
      " [5.77170402e-02 8.98391366e-01 4.26079929e-02 1.28369732e-03]\n",
      " [6.50390936e-03 1.70003623e-01 1.33396789e-01 6.90095663e-01]\n",
      " [1.75590422e-02 9.59681869e-01 2.11920682e-02 1.56714104e-03]\n",
      " [5.91094673e-01 3.79278094e-01 2.90199872e-02 6.07241411e-04]\n",
      " [4.55378462e-03 3.05006772e-01 6.77376032e-01 1.30633842e-02]\n",
      " [2.91912700e-03 5.84223382e-02 6.91168904e-01 2.47489601e-01]\n",
      " [4.71873628e-03 5.15474260e-01 1.83741480e-01 2.96065480e-01]\n",
      " [3.97723109e-01 4.69123095e-01 1.14381440e-01 1.87722966e-02]\n",
      " [1.25595793e-01 6.19443774e-01 2.50858217e-01 4.10218397e-03]\n",
      " [4.53103363e-04 2.11517774e-02 1.45329125e-02 9.63862181e-01]\n",
      " [1.40549312e-03 4.08539027e-02 3.51196900e-02 9.22620952e-01]\n",
      " [1.02342814e-02 9.73046541e-01 1.25315627e-02 4.18770732e-03]\n",
      " [1.55002996e-01 7.60513484e-01 8.07369202e-02 3.74660525e-03]\n",
      " [6.91413460e-03 2.53462821e-01 7.37287283e-01 2.33572815e-03]\n",
      " [3.44235480e-01 6.29990458e-01 2.57651471e-02 8.86926591e-06]\n",
      " [1.06538017e-03 9.42279026e-03 1.48461442e-02 9.74665642e-01]\n",
      " [5.44726267e-04 1.41918724e-02 2.45159189e-03 9.82811749e-01]\n",
      " [1.14509240e-02 4.76210825e-02 9.62410048e-02 8.44686925e-01]\n",
      " [5.86679205e-04 2.15720851e-02 3.16166505e-02 9.46224570e-01]\n",
      " [5.53336777e-02 7.56570220e-01 1.83648199e-01 4.44790954e-03]\n",
      " [5.45610525e-02 5.70055902e-01 3.69588107e-01 5.79494750e-03]\n",
      " [4.86204820e-03 2.10897960e-02 9.72717166e-01 1.33093446e-03]\n",
      " [1.16061084e-02 9.81654525e-01 6.71764137e-03 2.15921118e-05]\n",
      " [1.77426577e-01 5.47735631e-01 5.23604378e-02 2.22477317e-01]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_resnet50 = custom_vgg_model.predict(X_test)\n",
    "print(Y_pred_resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 1 1 2 2 1 1 2 1 3 2 3 3 2 1 3 3 2 1 3 1 0 0 1 3 3 1 3 2 1 2 2 2 3 2\n",
      " 1 3 2 1 1 1 1 1 1 2 0 2 0 2 3 1 1 2 2 1 2 3 1 3 1 1 3 1 1 1 2 3 2 1 1 2 1\n",
      " 3 0 1 3 1 2 1 1 1 2 2 1 2 3 1 2 2 1 1 0 3 1 2 2 2 3 1 2 1 1 1 3 1 3 2 2 2\n",
      " 3 2 1 2 2 3 2 3 2 2 1 2 1 2 2 1 2 1 1 2 3 1 1 1 1 1 2 1 3 1 0 2 2 1 1 1 3\n",
      " 3 1 1 2 1 3 3 3 3 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_resnet50 = np.argmax(Y_pred_VGG, axis=1)\n",
    "print(Y_pred_resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 31  3  0]\n",
      " [ 0 33  7  0]\n",
      " [ 0  1 32  0]\n",
      " [ 0  4 10 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), Y_pred_resnet50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here my resnet50 has vanishing gradient where the low layers of the network have not learnt the weights properly ,hence it caused me a saturated validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 37s 230ms/step\n",
      "Test Loss: 1.8777658026895405\n",
      "Test Accuracy: 0.20370370149612427\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print('Test Loss:', score[0])\n",
    "print('Test Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasnfer learning--AlexNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#3\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#4\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),strides=(4,4), padding='valid',kernel_initializer='normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#3\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#4\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 3rd Dense Layer\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 4004      \n",
      "=================================================================\n",
      "Total params: 28,083,756\n",
      "Trainable params: 28,062,620\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the AlexNet on the agumented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 646 samples, validate on 162 samples\n",
      "Epoch 1/10\n",
      "646/646 [==============================] - 48s 75ms/step - loss: 3.2571 - accuracy: 0.3777 - val_loss: 181.8861 - val_accuracy: 0.2963\n",
      "Epoch 2/10\n",
      "646/646 [==============================] - 45s 69ms/step - loss: 1.3521 - accuracy: 0.4768 - val_loss: 19.4399 - val_accuracy: 0.2160\n",
      "Epoch 3/10\n",
      "646/646 [==============================] - 44s 68ms/step - loss: 1.1359 - accuracy: 0.5464 - val_loss: 4.1014 - val_accuracy: 0.3086\n",
      "Epoch 4/10\n",
      "646/646 [==============================] - 45s 70ms/step - loss: 1.2971 - accuracy: 0.5093 - val_loss: 6.2348 - val_accuracy: 0.2222\n",
      "Epoch 5/10\n",
      "646/646 [==============================] - 44s 68ms/step - loss: 1.0998 - accuracy: 0.5882 - val_loss: 3.9533 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "646/646 [==============================] - 44s 69ms/step - loss: 1.0405 - accuracy: 0.6084 - val_loss: 1.9602 - val_accuracy: 0.3889\n",
      "Epoch 7/10\n",
      "646/646 [==============================] - 44s 68ms/step - loss: 1.0227 - accuracy: 0.6115 - val_loss: 1.7633 - val_accuracy: 0.4383\n",
      "Epoch 8/10\n",
      "646/646 [==============================] - 44s 68ms/step - loss: 0.9937 - accuracy: 0.6331 - val_loss: 3.6853 - val_accuracy: 0.3827\n",
      "Epoch 9/10\n",
      "646/646 [==============================] - 45s 69ms/step - loss: 0.8653 - accuracy: 0.6502 - val_loss: 1.8423 - val_accuracy: 0.4383\n",
      "Epoch 10/10\n",
      "646/646 [==============================] - 44s 68ms/step - loss: 0.8289 - accuracy: 0.6579 - val_loss: 2.1219 - val_accuracy: 0.4136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1db92aaf320>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epoch, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69285428e-04 5.76884905e-03 9.94008303e-01 5.35621548e-05]\n",
      " [9.16368049e-03 3.68106253e-02 9.51664209e-01 2.36153742e-03]\n",
      " [6.36741221e-02 7.43850052e-01 1.91626221e-01 8.49681208e-04]\n",
      " [2.53977120e-01 5.14868796e-01 2.20723346e-01 1.04307020e-02]\n",
      " [4.35439823e-03 6.58937693e-01 2.41861656e-01 9.48462635e-02]\n",
      " [7.92937633e-03 2.78308950e-02 9.58698273e-01 5.54152858e-03]\n",
      " [2.54746061e-03 9.55969915e-02 6.92997873e-01 2.08857715e-01]\n",
      " [3.26014496e-03 6.13350511e-01 8.14935565e-02 3.01895797e-01]\n",
      " [1.52806975e-02 9.45649266e-01 3.60467657e-02 3.02327774e-03]\n",
      " [5.50722843e-03 3.00024241e-01 6.07671082e-01 8.67974162e-02]\n",
      " [8.45628511e-03 9.35764372e-01 4.50397730e-02 1.07395751e-02]\n",
      " [1.79466943e-03 3.35684009e-02 8.81109852e-03 9.55825746e-01]\n",
      " [2.80715851e-03 1.97642446e-01 7.99285591e-01 2.64756556e-04]\n",
      " [2.35087820e-03 5.37705608e-02 1.76382557e-01 7.67496049e-01]\n",
      " [2.07872479e-03 1.11850649e-01 1.44399285e-01 7.41671324e-01]\n",
      " [5.59805194e-04 2.88881604e-02 9.69869375e-01 6.82645710e-04]\n",
      " [2.02170819e-01 7.12735474e-01 8.42621028e-02 8.31554644e-04]\n",
      " [1.73429996e-02 3.65646690e-01 2.08094075e-01 4.08916175e-01]\n",
      " [1.52552570e-03 1.34816999e-02 4.83376920e-01 5.01615822e-01]\n",
      " [5.99683039e-02 2.38821641e-01 6.90347195e-01 1.08629121e-02]\n",
      " [4.68178205e-02 4.97374386e-01 3.81740957e-01 7.40668476e-02]\n",
      " [2.30373669e-04 7.24896044e-03 1.14933483e-03 9.91371274e-01]\n",
      " [1.21057697e-01 8.16158593e-01 5.16500026e-02 1.11337341e-02]\n",
      " [4.76170808e-01 4.74496275e-01 4.81155142e-02 1.21733057e-03]\n",
      " [5.22578239e-01 3.88496637e-01 8.09273869e-02 7.99765345e-03]\n",
      " [2.67133825e-02 9.26355124e-01 4.04160395e-02 6.51551550e-03]\n",
      " [1.14691071e-03 4.29462418e-02 8.19486659e-03 9.47711945e-01]\n",
      " [8.57073974e-05 1.29000908e-02 7.28092641e-02 9.14204895e-01]\n",
      " [3.30791146e-01 6.43784165e-01 2.49282494e-02 4.96438704e-04]\n",
      " [4.80296090e-03 4.43843454e-02 4.65853550e-02 9.04227316e-01]\n",
      " [2.54174531e-03 5.83782196e-02 9.34658349e-01 4.42170678e-03]\n",
      " [2.50246935e-02 9.54712927e-01 2.01541260e-02 1.08186949e-04]\n",
      " [2.29130364e-05 8.47958727e-04 9.98866677e-01 2.62498303e-04]\n",
      " [1.11203026e-02 5.68397567e-02 9.27600026e-01 4.43999236e-03]\n",
      " [7.08773285e-02 1.93107873e-01 3.94954205e-01 3.41060519e-01]\n",
      " [1.24479202e-03 3.48474234e-02 1.46735653e-01 8.17172050e-01]\n",
      " [7.29548838e-03 1.54906258e-01 8.36755097e-01 1.04315602e-03]\n",
      " [1.78498833e-03 9.58214045e-01 3.97397876e-02 2.61115201e-04]\n",
      " [1.06538017e-03 9.42279026e-03 1.48461442e-02 9.74665642e-01]\n",
      " [5.09802339e-05 7.61959469e-04 9.98938859e-01 2.48185126e-04]\n",
      " [7.23530073e-03 8.65754843e-01 1.17981106e-01 9.02877003e-03]\n",
      " [1.42603204e-01 7.75770247e-01 8.02244022e-02 1.40210905e-03]\n",
      " [5.50759677e-03 8.92377555e-01 9.98687074e-02 2.24607950e-03]\n",
      " [3.34748685e-01 4.61008489e-01 1.99589163e-01 4.65376303e-03]\n",
      " [2.94856578e-02 9.03962553e-01 6.64229393e-02 1.28755681e-04]\n",
      " [5.08377841e-03 7.33200192e-01 2.61309206e-01 4.06785082e-04]\n",
      " [2.06650784e-05 1.26656583e-02 9.87266481e-01 4.71613093e-05]\n",
      " [4.87562984e-01 4.43320215e-01 6.74276054e-02 1.68915570e-03]\n",
      " [2.40504436e-04 2.23916676e-02 9.73224580e-01 4.14327066e-03]\n",
      " [5.33236206e-01 3.28238428e-01 1.31655976e-01 6.86937431e-03]\n",
      " [3.04816203e-04 7.84253981e-03 9.90426123e-01 1.42649305e-03]\n",
      " [6.70772940e-02 4.19696569e-01 6.57480136e-02 4.47478056e-01]\n",
      " [6.18523024e-02 6.68150783e-01 1.70894876e-01 9.91020873e-02]\n",
      " [4.40984266e-03 6.37988687e-01 3.57114136e-01 4.87371726e-04]\n",
      " [3.17137834e-04 3.44430818e-03 9.95386541e-01 8.51927849e-04]\n",
      " [2.36670226e-02 1.33937493e-01 8.11056435e-01 3.13390344e-02]\n",
      " [2.77707458e-01 6.62431300e-01 5.93705289e-02 4.90720209e-04]\n",
      " [3.00752610e-04 6.26905682e-03 9.92897511e-01 5.32675476e-04]\n",
      " [1.72762689e-03 1.22736529e-01 3.80036607e-02 8.37532222e-01]\n",
      " [4.44728822e-01 4.77533162e-01 7.32299164e-02 4.50810371e-03]\n",
      " [1.94162095e-03 3.32322381e-02 6.37688488e-02 9.01057243e-01]\n",
      " [2.75847882e-01 3.97687912e-01 3.21344644e-01 5.11947181e-03]\n",
      " [2.67846614e-01 3.71987164e-01 1.32627502e-01 2.27538690e-01]\n",
      " [1.62706291e-03 3.23702917e-02 5.02645411e-02 9.15738106e-01]\n",
      " [1.00891285e-01 7.60674953e-01 1.21243611e-01 1.71901062e-02]\n",
      " [2.01224655e-01 6.29394948e-01 1.63602918e-01 5.77750336e-03]\n",
      " [4.27177995e-02 7.04026520e-01 2.44113863e-01 9.14181583e-03]\n",
      " [1.23619111e-05 3.53532028e-03 9.96359289e-01 9.30453534e-05]\n",
      " [5.20840054e-03 1.19193740e-01 1.77944005e-02 8.57803404e-01]\n",
      " [9.83593892e-03 9.05762538e-02 8.98673952e-01 9.13940486e-04]\n",
      " [3.75849009e-01 4.05382097e-01 1.56053185e-01 6.27157092e-02]\n",
      " [4.07203645e-01 4.43462998e-01 1.16756409e-01 3.25769149e-02]\n",
      " [7.19141855e-04 2.01573148e-02 9.49130714e-01 2.99928226e-02]\n",
      " [2.06589878e-01 6.28172159e-01 6.53567016e-02 9.98812914e-02]\n",
      " [3.82098369e-04 2.47184858e-02 3.12200487e-01 6.62698865e-01]\n",
      " [4.69014615e-01 3.41011584e-01 1.84429124e-01 5.54463407e-03]\n",
      " [1.37499468e-02 8.54645312e-01 1.30988002e-01 6.16715755e-04]\n",
      " [8.72348342e-03 1.00589640e-01 1.68479562e-01 7.22207308e-01]\n",
      " [3.12897831e-01 6.64193630e-01 2.23017074e-02 6.06814981e-04]\n",
      " [3.92282428e-03 1.23152070e-01 8.62682819e-01 1.02422182e-02]\n",
      " [1.57755762e-02 6.23753846e-01 2.26396650e-01 1.34073928e-01]\n",
      " [4.65442536e-05 9.87169504e-01 1.27778333e-02 6.07856464e-06]\n",
      " [5.67355379e-02 9.03276801e-01 3.77921611e-02 2.19542510e-03]\n",
      " [1.09056188e-02 1.03586480e-01 7.65852034e-01 1.19655877e-01]\n",
      " [5.21585789e-05 2.09316713e-04 9.99677181e-01 6.14164019e-05]\n",
      " [4.67729941e-03 9.23214734e-01 7.16574714e-02 4.50590509e-04]\n",
      " [2.02599913e-04 3.82460713e-01 6.16265357e-01 1.07124459e-03]\n",
      " [8.10896512e-03 1.44824401e-01 6.56071231e-02 7.81459451e-01]\n",
      " [1.68609560e-01 7.77516186e-01 4.35473509e-02 1.03268735e-02]\n",
      " [8.35992396e-02 3.57650459e-01 5.03210127e-01 5.55401966e-02]\n",
      " [4.12269775e-03 8.34430456e-02 9.10688937e-01 1.74532470e-03]\n",
      " [8.03415460e-05 9.91424680e-01 8.28030985e-03 2.14622647e-04]\n",
      " [1.62492111e-01 6.41755581e-01 1.49407789e-01 4.63444889e-02]\n",
      " [6.92494094e-01 2.45377406e-01 5.82040884e-02 3.92443035e-03]\n",
      " [2.37924256e-03 1.31237842e-02 3.00262333e-03 9.81494308e-01]\n",
      " [2.03952968e-01 7.47578025e-01 4.64990102e-02 1.96997379e-03]\n",
      " [8.41360632e-03 1.68896560e-02 9.74149525e-01 5.47232397e-04]\n",
      " [6.16453472e-04 2.87484447e-03 9.96130705e-01 3.77935125e-04]\n",
      " [4.20294702e-04 1.00551099e-02 9.87867951e-01 1.65667327e-03]\n",
      " [7.97251705e-03 1.07950114e-01 1.57993641e-02 8.68277967e-01]\n",
      " [1.70862943e-01 6.48131549e-01 6.45978823e-02 1.16407566e-01]\n",
      " [2.91766226e-03 4.39654030e-02 9.03604507e-01 4.95123751e-02]\n",
      " [3.09222341e-01 5.96992254e-01 9.25140232e-02 1.27139466e-03]\n",
      " [1.26837417e-02 8.63974571e-01 9.91479307e-02 2.41937842e-02]\n",
      " [6.47994950e-02 5.36132634e-01 1.84324518e-01 2.14743361e-01]\n",
      " [1.32207060e-03 2.64467336e-02 5.39257424e-03 9.66838598e-01]\n",
      " [3.29960376e-01 4.03589070e-01 2.46887922e-01 1.95626821e-02]\n",
      " [1.18063192e-03 3.51310298e-02 6.07851483e-02 9.02903199e-01]\n",
      " [2.75985757e-03 1.34671077e-01 4.97348487e-01 3.65220487e-01]\n",
      " [4.00693789e-05 1.41326024e-03 9.98517931e-01 2.87136008e-05]\n",
      " [2.20635463e-03 5.78891393e-03 9.91781414e-01 2.23388633e-04]\n",
      " [6.87562628e-04 5.38979471e-02 7.60871321e-02 8.69327307e-01]\n",
      " [1.57620834e-05 1.95331313e-02 9.80397344e-01 5.37615160e-05]\n",
      " [3.12602073e-01 5.35903215e-01 1.25710830e-01 2.57837716e-02]\n",
      " [6.97999001e-02 6.16595261e-02 8.22598755e-01 4.59417738e-02]\n",
      " [4.21653315e-02 3.87203276e-01 5.60228705e-01 1.04027148e-02]\n",
      " [5.80530055e-03 3.88876572e-02 1.59410641e-01 7.95896411e-01]\n",
      " [2.61962507e-03 6.86430139e-03 9.62933660e-01 2.75825262e-02]\n",
      " [8.83715169e-04 9.23819765e-02 4.33923341e-02 8.63341987e-01]\n",
      " [1.93096363e-04 4.31535579e-02 5.68046212e-01 3.88607144e-01]\n",
      " [1.97567511e-04 4.14146557e-02 9.57004666e-01 1.38313661e-03]\n",
      " [6.45390078e-02 8.71626616e-01 5.55281341e-02 8.30623507e-03]\n",
      " [9.01513360e-03 1.10099256e-01 5.76422155e-01 3.04463387e-01]\n",
      " [1.69377044e-01 6.77354455e-01 1.02636069e-01 5.06324433e-02]\n",
      " [1.14724450e-02 3.52680795e-02 9.46673155e-01 6.58626808e-03]\n",
      " [1.63307879e-03 1.17803179e-02 9.83681440e-01 2.90516787e-03]\n",
      " [4.01735865e-02 8.19310188e-01 1.13854744e-01 2.66614798e-02]\n",
      " [2.89969641e-04 3.05243302e-03 9.83789206e-01 1.28683802e-02]\n",
      " [5.59770837e-02 9.04359221e-01 2.04691123e-02 1.91946812e-02]\n",
      " [3.20284694e-01 5.48547685e-01 9.90308300e-02 3.21368538e-02]\n",
      " [4.82338481e-02 1.51111126e-01 7.72837520e-01 2.78174654e-02]\n",
      " [1.02529721e-03 1.70117505e-02 1.21132797e-02 9.69849646e-01]\n",
      " [3.60798359e-01 4.83950317e-01 1.54514104e-01 7.37128605e-04]\n",
      " [8.60799700e-02 7.61519790e-01 1.45182610e-01 7.21753296e-03]\n",
      " [3.65251750e-02 4.36060935e-01 1.61628231e-01 3.65785658e-01]\n",
      " [1.11536816e-01 6.95759833e-01 5.45425788e-02 1.38160810e-01]\n",
      " [5.97021030e-03 6.28845811e-01 3.64480853e-01 7.03158788e-04]\n",
      " [7.43210403e-05 3.62050207e-03 9.95887458e-01 4.17819101e-04]\n",
      " [5.77170402e-02 8.98391366e-01 4.26079929e-02 1.28369732e-03]\n",
      " [6.50390936e-03 1.70003623e-01 1.33396789e-01 6.90095663e-01]\n",
      " [1.75590422e-02 9.59681869e-01 2.11920682e-02 1.56714104e-03]\n",
      " [5.91094673e-01 3.79278094e-01 2.90199872e-02 6.07241411e-04]\n",
      " [4.55378462e-03 3.05006772e-01 6.77376032e-01 1.30633842e-02]\n",
      " [2.91912700e-03 5.84223382e-02 6.91168904e-01 2.47489601e-01]\n",
      " [4.71873628e-03 5.15474260e-01 1.83741480e-01 2.96065480e-01]\n",
      " [3.97723109e-01 4.69123095e-01 1.14381440e-01 1.87722966e-02]\n",
      " [1.25595793e-01 6.19443774e-01 2.50858217e-01 4.10218397e-03]\n",
      " [4.53103363e-04 2.11517774e-02 1.45329125e-02 9.63862181e-01]\n",
      " [1.40549312e-03 4.08539027e-02 3.51196900e-02 9.22620952e-01]\n",
      " [1.02342814e-02 9.73046541e-01 1.25315627e-02 4.18770732e-03]\n",
      " [1.55002996e-01 7.60513484e-01 8.07369202e-02 3.74660525e-03]\n",
      " [6.91413460e-03 2.53462821e-01 7.37287283e-01 2.33572815e-03]\n",
      " [3.44235480e-01 6.29990458e-01 2.57651471e-02 8.86926591e-06]\n",
      " [1.06538017e-03 9.42279026e-03 1.48461442e-02 9.74665642e-01]\n",
      " [5.44726267e-04 1.41918724e-02 2.45159189e-03 9.82811749e-01]\n",
      " [1.14509240e-02 4.76210825e-02 9.62410048e-02 8.44686925e-01]\n",
      " [5.86679205e-04 2.15720851e-02 3.16166505e-02 9.46224570e-01]\n",
      " [5.53336777e-02 7.56570220e-01 1.83648199e-01 4.44790954e-03]\n",
      " [5.45610525e-02 5.70055902e-01 3.69588107e-01 5.79494750e-03]\n",
      " [4.86204820e-03 2.10897960e-02 9.72717166e-01 1.33093446e-03]\n",
      " [1.16061084e-02 9.81654525e-01 6.71764137e-03 2.15921118e-05]\n",
      " [1.77426577e-01 5.47735631e-01 5.23604378e-02 2.22477317e-01]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_alex = custom_vgg_model.predict(X_test)\n",
    "print(Y_pred_alex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 1 1 2 2 1 1 2 1 3 2 3 3 2 1 3 3 2 1 3 1 0 0 1 3 3 1 3 2 1 2 2 2 3 2\n",
      " 1 3 2 1 1 1 1 1 1 2 0 2 0 2 3 1 1 2 2 1 2 3 1 3 1 1 3 1 1 1 2 3 2 1 1 2 1\n",
      " 3 0 1 3 1 2 1 1 1 2 2 1 2 3 1 2 2 1 1 0 3 1 2 2 2 3 1 2 1 1 1 3 1 3 2 2 2\n",
      " 3 2 1 2 2 3 2 3 2 2 1 2 1 2 2 1 2 1 1 2 3 1 1 1 1 1 2 1 3 1 0 2 2 1 1 1 3\n",
      " 3 1 1 2 1 3 3 3 3 1 1 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "Y_pred_alex = np.argmax(Y_pred_alex, axis=1)\n",
    "print(Y_pred_alex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 31  3  0]\n",
      " [ 0 33  7  0]\n",
      " [ 0  1 32  0]\n",
      " [ 0  4 10 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), Y_pred_alex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/5 [===================================] - 3s 575ms/step\n"
     ]
    }
   ],
   "source": [
    "alexnet_model_evaluate = model.evaluate_generator(ftest_generator, verbose=1, steps=X_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40158894658088684, 0.4135802388191223]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet_model_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG has been the best model for this data than Resnet50 and Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
